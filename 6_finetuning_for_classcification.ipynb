{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 不同类型的微调\n",
    "\n",
    "微调语言模型最常见的方法是```指令微调```和```分类微调```。指令微调通过在一组任务上使用特定指令训练模型，用以提升模型对自然语言提示中任务描述的理解和执行能力，如图 6.2 所示。\n",
    "\n",
    "![Alt text](imgs/PixPin_2025-07-24_22-45-29.png)\n",
    "\n",
    "在分类微调中，模型被训练用来识别特定的一组类别标签，比如“垃圾短信”和“非垃圾短信”。分类任务的应用不仅限于 LLM 和电子邮件过滤，还包括从图像中识别不同种类的植物、将新闻分类到体育、政治或科技等主题，以及在医学影像中区分良性和恶性肿瘤。\n",
    "\n",
    "但有一个关键点需要注意，经过分类微调的模型**只能预测训练中遇到的类别**。例如，它可以判断某内容是‘垃圾短信’还是‘非垃圾短信’（如图 6.3 所示），但不能对输入文本提供其他方面的信息。\n",
    "\n",
    "> [!NOTE]\n",
    "> 选择合适的微调方式\n",
    "> \n",
    "> 指令微调提升了模型基于用户指令进行理解和生成响应的能力。它适用于需要基于复杂用户指令处理多任务的模型，增强模型的灵活性和交互质量。而分类微调则适合需要将数据精确分类为预定义类别的任务，例如情感分析或垃圾短信检测。\n",
    "> \n",
    "> 虽然指令微调用途更广泛，但需要更大的数据集和更多的计算资源，才能训练出能胜任多种任务的模型。相比之下，分类微调所需的数据和计算量更少，但用途局限于模型已训练的特定类别。\n",
    "\n",
    "## 6.2 准备数据集\n",
    "\n",
    "![Alt text](imgs/PixPin_2025-07-24_23-06-36.png)\n",
    "\n",
    "为了提供一个直观实用的分类微调示例，我们将采用一个包含垃圾消息和非垃圾消息的文本消息数据集。\n",
    "\n",
    "注意，这里讨论的是通过手机发送的短信，而不是电子邮件。不过，相同的步骤也适用于电子邮件分类，感兴趣的读者可以在附录 B 的参考部分找到邮件垃圾分类数据集的链接。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"sms_spam_collection.zip\"\n",
    "extracted_path = \"sms_spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
    "\n",
    "def download_and_unzip_spam_data(url,zip_path, extracted_path, data_file_path):\n",
    "    if data_file_path.exists():\n",
    "        print(f\"{data_file_path} already exists. Skipping download and extraction.\")\n",
    "    \n",
    "    with urllib.request.urlopen(url) as response:          #A\n",
    "        with open(zip_path, \"wb\") as out_file:\n",
    "            out_file.write(response.read())\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:        #B\n",
    "        zip_ref.extractall(extracted_path)\n",
    "\n",
    "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
    "    os.rename(original_file_path, data_file_path)          #C\n",
    "    print(f\"File downloaded and saved as {data_file_path}\")\n",
    "\n",
    "download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n",
    "\n",
    "#A 下载数据集\n",
    "#B 解压数据集\n",
    "#C 为解压的数据集文件设置.csv文件扩展名\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                               Text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"])\n",
    "df      #A\n",
    "\n",
    "#A 在 Jupyter Notebook 中可以直接渲染数据，或者用 print(df) 命令显示数据内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Label\"].value_counts())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了简化起见，同时也因为我们倾向于使用小数据集进行教学（这便于更快地微调 LLM），我们选择对数据集进行下采样，每个类别保留 747 个样本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     747\n",
      "spam    747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Listing 6.2 Creating a balanced dataset\n",
    "def create_balanced_dataset(df):\n",
    "    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]                                 #A\n",
    "    ham_subset = df[df[\"Label\"] == \"ham\"].sample(num_spam, random_state=123)      #B\n",
    "    balanced_df = pd.concat([ham_subset, df[df[\"Label\"] == \"spam\"]])              #C\n",
    "    return balanced_df\n",
    "\n",
    "balanced_df = create_balanced_dataset(df)\n",
    "print(balanced_df[\"Label\"].value_counts())\n",
    "\n",
    "\n",
    "#A 统计垃圾短信的实例数量\n",
    "#B 随机抽取正常邮件实例，使其数量与垃圾短信实例相同。\n",
    "#C 将正常短信子集与垃圾短信合并\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4307</th>\n",
       "      <td>0</td>\n",
       "      <td>Awww dat is sweet! We can think of something t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4138</th>\n",
       "      <td>0</td>\n",
       "      <td>Just got to  &amp;lt;#&amp;gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4831</th>\n",
       "      <td>0</td>\n",
       "      <td>The word \"Checkmate\" in chess comes from the P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4461</th>\n",
       "      <td>0</td>\n",
       "      <td>This is wishing you a great day. Moji told me ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5440</th>\n",
       "      <td>0</td>\n",
       "      <td>Thank you. do you generally date the brothas?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5537</th>\n",
       "      <td>1</td>\n",
       "      <td>Want explicit SEX in 30 secs? Ring 02073162414...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5540</th>\n",
       "      <td>1</td>\n",
       "      <td>ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5547</th>\n",
       "      <td>1</td>\n",
       "      <td>Had your contract mobile 11 Mnths? Latest Moto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>1</td>\n",
       "      <td>REMINDER FROM O2: To get 2.50 pounds free call...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>1</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1494 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label                                               Text\n",
       "4307      0  Awww dat is sweet! We can think of something t...\n",
       "4138      0                             Just got to  &lt;#&gt;\n",
       "4831      0  The word \"Checkmate\" in chess comes from the P...\n",
       "4461      0  This is wishing you a great day. Moji told me ...\n",
       "5440      0      Thank you. do you generally date the brothas?\n",
       "...     ...                                                ...\n",
       "5537      1  Want explicit SEX in 30 secs? Ring 02073162414...\n",
       "5540      1  ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...\n",
       "5547      1  Had your contract mobile 11 Mnths? Latest Moto...\n",
       "5566      1  REMINDER FROM O2: To get 2.50 pounds free call...\n",
       "5567      1  This is the 2nd time we have tried 2 contact u...\n",
       "\n",
       "[1494 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们还需创建一个random_split函数，将数据集划分为三部分：70%用于训练，10%用于验证，20%用于测试。这些比例是机器学习中用于训练、调整和评估模型的常见划分比例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 6.3 Splitting the dataset\n",
    "def random_split(df, train_frac, validation_frac):\n",
    "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)     #A\n",
    "\n",
    "    train_end = int(len(df) * train_frac)                               #B\n",
    "    validation_end = train_end + int(len(df) * validation_frac)\n",
    "\n",
    "    train_df = df[:train_end]                                           #C\n",
    "    validation_df = df[train_end:validation_end]\n",
    "    test_df = df[validation_end:]\n",
    "\n",
    "    return train_df, validation_df, test_df\n",
    "\n",
    "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)  #D\n",
    "\n",
    "\n",
    "#A 将整个 DataFrame 随机打乱\n",
    "#B 计算数据分割的索引\n",
    "#C 分割 DataFrame\n",
    "#D 测试集默认大小为 0.2（即剩余部分）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the train file is exist\n",
      "the validation file is exist\n",
      "the test file is exist\n"
     ]
    }
   ],
   "source": [
    "csv_path = \"chapter06\"\n",
    "train_csv_path = Path(csv_path) / \"train.csv\"\n",
    "validation_csv_path = Path(csv_path) / \"validation.csv\"\n",
    "test_csv_path = Path(csv_path) / \"test.csv\"\n",
    "if train_csv_path.exists() is False:\n",
    "    train_df.to_csv(train_csv_path, index=None)\n",
    "    print(f\"training csv file is saved as {train_csv_path}\")\n",
    "else:\n",
    "    print(\"the train file is exist\")\n",
    "\n",
    "if validation_csv_path.exists() is False:\n",
    "    validation_df.to_csv(validation_csv_path, index=None)\n",
    "    print(f\"validation csv file is saved as {validation_csv_path}\")\n",
    "else:\n",
    "    print(\"the validation file is exist\")\n",
    "\n",
    "if test_csv_path.exists() is False:\n",
    "    test_df.to_csv(test_csv_path, index=None)\n",
    "    print(f\"test csv file is saved as {test_csv_path}\")\n",
    "else:\n",
    "    print(\"the test file is exist\")\n",
    "\n",
    "\n",
    "#validation_df.to_csv(\"validation.csv\", index=None)\n",
    "#test_df.to_csv(\"test.csv\", index=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接着，我们需要实例化数据加载器。但在此之前，我们首先需要实现一个 PyTorch Dataset，用于定义数据的加载和处理方式。\n",
    "\n",
    "为此，我们定义了SpamDataset类，实现了图 6.6 中展示的概念。该类负责处理多个关键任务：它识别训练数据集中最长的序列，对文本消息进行编码，并确保通过填充 token 将其他序列补齐到与最长序列相同的长度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 6.4 Setting up a Pytorch Dataset class\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SpamDataset(Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "\n",
    "        self.encoded_texts = [                                      #A\n",
    "            tokenizer.encode(text) for text in self.data[\"Text\"]\n",
    "        ]\n",
    "\n",
    "        if max_length is None:\n",
    "            self.max_length = self._longest_encoded_length()\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "\n",
    "            self.encoded_texts = [                                  #B\n",
    "                encoded_text[:self.max_length] for encoded_text in self.encoded_texts\n",
    "            ]\n",
    "\n",
    "        self.encoded_texts = [                                      #C\n",
    "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text)) for encoded_text in self.encoded_texts\n",
    "        ]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        encoded = self.encoded_texts[index]\n",
    "        label = self.data.iloc[index][\"Label\"]\n",
    "        return (\n",
    "            torch.tensor(encoded, dtype=torch.long),\n",
    "            torch.tensor(label, dtype=torch.long)\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def _longest_encoded_length(self):\n",
    "        max_length = 0\n",
    "        for encoded_text in self.encoded_texts:\n",
    "            encoded_length = len(encoded_text)\n",
    "            if encoded_length > max_length:\n",
    "                max_length = encoded_length\n",
    "        return max_length\n",
    "\n",
    "\n",
    "#A 对文本进行预分词\n",
    "#B 若序列超过最大长度则进行截断\n",
    "#C 将序列填充至最长序列长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SpamDataset(\n",
    "    csv_file=\"chapter06/train.csv\",\n",
    "    max_length=None,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "print(train_dataset.max_length)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "代码输出了 120，表明最长的序列不超过 120 个 token，这也是文本消息的常见长度。值得注意的是，我们之前预训练的模型的上下文长度限制为 1,024 个 token，因此可以处理最长 1,024 个 token 的序列。如果数据集中包含更长的文本，可以在创建训练数据集时传入 max_length=1024 参数，以确保数据不会超出模型支持的输入（上下文）长度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "120\n"
     ]
    }
   ],
   "source": [
    "val_dataset = SpamDataset(\n",
    "    csv_file=\"chapter06/validation.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "test_dataset = SpamDataset(\n",
    "    csv_file=\"chapter06/test.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "print(val_dataset.max_length)\n",
    "print(test_dataset.max_length)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将以上的数据集作为输入，我们就可以实例化数据加载器（可以回顾第 2 章中的操作）。然而，在本例中，目标表示的是类别标签，而非文本中的下一个 token。例如，选择```批量大小为 8 ```时，每个批次包含 8 个长度为 120 的训练样本和相应的类别标签，如图 6.7 所示。\n",
    "\n",
    "![Alt text](imgs/PixPin_2025-07-25_00-47-25.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 6.5 Creating PyTorch data loaders\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0                  #A\n",
    "batch_size = 8\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "#A 此设置可确保与大多数计算机兼容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size       : 1045 样本\n",
      "Batch size         : 8\n",
      "Number of batches  : 130\n",
      "\n",
      "--- Batch tensor shapes ---\n",
      "input_batch  : torch.Size([8, 120])  (dtype=torch.int64)\n",
      "target_batch : torch.Size([8]) (dtype=torch.int64)\n",
      "\n",
      "--- First sample preview ---\n",
      "input  : tensor([   56,    64,   655,  5149,   450,    83,   294,    83,  4519,   492,\n",
      "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256])\n",
      "target : tensor(0)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 1) 批次数 & 数据条数\n",
    "print(f\"Dataset size       : {len(train_loader.dataset)} 样本\")\n",
    "print(f\"Batch size         : {train_loader.batch_size}\")\n",
    "print(f\"Number of batches  : {len(train_loader)}\")\n",
    "\n",
    "# 2) 取一个 batch 看形状\n",
    "input_batch, target_batch = next(iter(train_loader))\n",
    "print(\"\\n--- Batch tensor shapes ---\")\n",
    "print(f\"input_batch  : {input_batch.shape}  (dtype={input_batch.dtype})\")\n",
    "print(f\"target_batch : {target_batch.shape} (dtype={target_batch.dtype})\")\n",
    "\n",
    "# 3) 查看前 1~2 行具体内容（按你的数据类型自由调整打印方式）\n",
    "print(\"\\n--- First sample preview ---\")\n",
    "print(\"input  :\", input_batch[0])\n",
    "print(\"target :\", target_batch[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 training batches\n",
      "19 validation batches\n",
      "38 test batches\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(train_loader)} training batches\")\n",
    "print(f\"{len(val_loader)} validation batches\")\n",
    "print(f\"{len(test_loader)} test batches\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 使用预训练权重初始化模型\n",
    "\n",
    "![Alt text](imgs/PixPin_2025-07-25_00-51-51.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257, # Vocabulary size\n",
    "    \"context_length\": 1024, # Context length\n",
    "    \"drop_rate\": 0.0, # Dropout rate\n",
    "    \"qkv_bias\": True # Query-key-value bias\n",
    "}\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "assert train_dataset.max_length <= BASE_CONFIG[\"context_length\"], (\n",
    "    f\"Dataset length {train_dataset.max_length} exceeds model's context \"\n",
    "    f\"length {BASE_CONFIG['context_length']}. Reinitialize data sets with \"\n",
    "    f\"`max_length={BASE_CONFIG['context_length']}`\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\checkpoint\n",
      "File already exists and is up-to-date: gpt2\\124M\\encoder.json\n",
      "File already exists and is up-to-date: gpt2\\124M\\hparams.json\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2\\124M\\vocab.bpe\n",
      "Output text:\n",
      " Every effort moves you toward the ultimate goal. It's important not to take shortcuts, but not to take shortcuts that only benefit those most at the\n"
     ]
    }
   ],
   "source": [
    "# Copyright (c) Sebastian Raschka under Apache License 2.0 (see LICENSE.txt).\n",
    "# Source for \"Build a Large Language Model From Scratch\"\n",
    "#   - https://www.manning.com/books/build-a-large-language-model-from-scratch\n",
    "# Code: https://github.com/rasbt/LLMs-from-scratch\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import urllib.request\n",
    "\n",
    "# import requests\n",
    "import tensorflow as tf\n",
    "import tiktoken\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Import from local files\n",
    "from chapter05.previous_chapters import GPTModel\n",
    "\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text)\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)  # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0)  # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "\n",
    "def download_and_load_gpt2(model_size, models_dir):\n",
    "    # Validate model size\n",
    "    allowed_sizes = (\"124M\", \"355M\", \"774M\", \"1558M\")\n",
    "    if model_size not in allowed_sizes:\n",
    "        raise ValueError(f\"Model size not in {allowed_sizes}\")\n",
    "\n",
    "    # Define paths\n",
    "    model_dir = os.path.join(models_dir, model_size)\n",
    "    base_url = \"https://openaipublic.blob.core.windows.net/gpt-2/models\"\n",
    "    filenames = [\n",
    "        \"checkpoint\", \"encoder.json\", \"hparams.json\",\n",
    "        \"model.ckpt.data-00000-of-00001\", \"model.ckpt.index\",\n",
    "        \"model.ckpt.meta\", \"vocab.bpe\"\n",
    "    ]\n",
    "\n",
    "    # Download files\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    for filename in filenames:\n",
    "        file_url = os.path.join(base_url, model_size, filename)\n",
    "        file_path = os.path.join(model_dir, filename)\n",
    "        download_file(file_url, file_path)\n",
    "\n",
    "    # Load settings and params\n",
    "    tf_ckpt_path = tf.train.latest_checkpoint(model_dir)\n",
    "    settings = json.load(open(os.path.join(model_dir, \"hparams.json\")))\n",
    "    params = load_gpt2_params_from_tf_ckpt(tf_ckpt_path, settings)\n",
    "\n",
    "    return settings, params\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "def download_file(url, destination):\n",
    "    # Send a GET request to download the file in streaming mode\n",
    "    response = requests.get(url, stream=True)\n",
    "\n",
    "    # Get the total file size from headers, defaulting to 0 if not present\n",
    "    file_size = int(response.headers.get(\"content-length\", 0))\n",
    "\n",
    "    # Check if file exists and has the same size\n",
    "    if os.path.exists(destination):\n",
    "        file_size_local = os.path.getsize(destination)\n",
    "        if file_size == file_size_local:\n",
    "            print(f\"File already exists and is up-to-date: {destination}\")\n",
    "            return\n",
    "\n",
    "    # Define the block size for reading the file\n",
    "    block_size = 1024  # 1 Kilobyte\n",
    "\n",
    "    # Initialize the progress bar with total file size\n",
    "    progress_bar_description = url.split(\"/\")[-1]  # Extract filename from URL\n",
    "    with tqdm(total=file_size, unit=\"iB\", unit_scale=True, desc=progress_bar_description) as progress_bar:\n",
    "        # Open the destination file in binary write mode\n",
    "        with open(destination, \"wb\") as file:\n",
    "            # Iterate over the file data in chunks\n",
    "            for chunk in response.iter_content(block_size):\n",
    "                progress_bar.update(len(chunk))  # Update progress bar\n",
    "                file.write(chunk)  # Write the chunk to the file\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def download_file(url, destination):\n",
    "    # Send a GET request to download the file\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        # Get the total file size from headers, defaulting to 0 if not present\n",
    "        file_size = int(response.headers.get(\"Content-Length\", 0))\n",
    "\n",
    "        # Check if file exists and has the same size\n",
    "        if os.path.exists(destination):\n",
    "            file_size_local = os.path.getsize(destination)\n",
    "            if file_size == file_size_local:\n",
    "                print(f\"File already exists and is up-to-date: {destination}\")\n",
    "                return\n",
    "\n",
    "        # Define the block size for reading the file\n",
    "        block_size = 1024  # 1 Kilobyte\n",
    "\n",
    "        # Initialize the progress bar with total file size\n",
    "        progress_bar_description = os.path.basename(url)  # Extract filename from URL\n",
    "        with tqdm(total=file_size, unit=\"iB\", unit_scale=True, desc=progress_bar_description) as progress_bar:\n",
    "            # Open the destination file in binary write mode\n",
    "            with open(destination, \"wb\") as file:\n",
    "                # Read the file in chunks and write to destination\n",
    "                while True:\n",
    "                    chunk = response.read(block_size)\n",
    "                    if not chunk:\n",
    "                        break\n",
    "                    file.write(chunk)\n",
    "                    progress_bar.update(len(chunk))  # Update progress bar\n",
    "\n",
    "\n",
    "def load_gpt2_params_from_tf_ckpt(ckpt_path, settings):\n",
    "    # Initialize parameters dictionary with empty blocks for each layer\n",
    "    params = {\"blocks\": [{} for _ in range(settings[\"n_layer\"])]}\n",
    "\n",
    "    # Iterate over each variable in the checkpoint\n",
    "    for name, _ in tf.train.list_variables(ckpt_path):\n",
    "        # Load the variable and remove singleton dimensions\n",
    "        variable_array = np.squeeze(tf.train.load_variable(ckpt_path, name))\n",
    "\n",
    "        # Process the variable name to extract relevant parts\n",
    "        variable_name_parts = name.split(\"/\")[1:]  # Skip the 'model/' prefix\n",
    "\n",
    "        # Identify the target dictionary for the variable\n",
    "        target_dict = params\n",
    "        if variable_name_parts[0].startswith(\"h\"):\n",
    "            layer_number = int(variable_name_parts[0][1:])\n",
    "            target_dict = params[\"blocks\"][layer_number]\n",
    "\n",
    "        # Recursively access or create nested dictionaries\n",
    "        for key in variable_name_parts[1:-1]:\n",
    "            target_dict = target_dict.setdefault(key, {})\n",
    "\n",
    "        # Assign the variable array to the last key\n",
    "        last_key = variable_name_parts[-1]\n",
    "        target_dict[last_key] = variable_array\n",
    "\n",
    "    return params\n",
    "\n",
    "\n",
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))\n",
    "\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params[\"wpe\"])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params[\"wte\"])\n",
    "\n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias,\n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias,\n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift,\n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift,\n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n",
    "\n",
    "\n",
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "\n",
    "    # For-loop is the same as before: Get logits, and only focus on last time step\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # New: Filter logits with top_k sampling\n",
    "        if top_k is not None:\n",
    "            # Keep only top_k values\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
    "\n",
    "        # New: Apply temperature scaling\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "\n",
    "            # Apply softmax to get probabilities\n",
    "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
    "\n",
    "            # Sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
    "\n",
    "        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
    "\n",
    "        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
    "            break\n",
    "\n",
    "        # Same as before: append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
    "\n",
    "    return idx\n",
    "\n",
    "\n",
    "def main(gpt_config, input_prompt, model_size):\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
    "\n",
    "    gpt = GPTModel(gpt_config)\n",
    "    load_weights_into_gpt(gpt, params)\n",
    "    gpt.to(device)\n",
    "    gpt.eval()\n",
    "\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    torch.manual_seed(123)\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=gpt,\n",
    "        idx=text_to_token_ids(input_prompt, tokenizer).to(device),\n",
    "        max_new_tokens=25,\n",
    "        context_size=gpt_config[\"context_length\"],\n",
    "        top_k=50,\n",
    "        temperature=1.0\n",
    "    )\n",
    "\n",
    "    print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    torch.manual_seed(123)\n",
    "\n",
    "    CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "    INPUT_PROMPT = \"Every effort moves you\"\n",
    "\n",
    "    BASE_CONFIG = {\n",
    "        \"vocab_size\": 50257,     # Vocabulary size\n",
    "        \"context_length\": 1024,  # Context length\n",
    "        \"drop_rate\": 0.0,        # Dropout rate\n",
    "        \"qkv_bias\": True         # Query-key-value bias\n",
    "    }\n",
    "\n",
    "    model_configs = {\n",
    "        \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "        \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "        \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "        \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "    }\n",
    "\n",
    "    model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "\n",
    "    BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "    main(BASE_CONFIG, INPUT_PROMPT, model_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\checkpoint\n",
      "File already exists and is up-to-date: gpt2\\124M\\encoder.json\n",
      "File already exists and is up-to-date: gpt2\\124M\\hparams.json\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2\\124M\\vocab.bpe\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size): #A\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]                           #B\n",
    "        with torch.no_grad():\n",
    "           logits = model(idx_cond)\n",
    "\n",
    "        logits = logits[:, -1, :]                                   #C\n",
    "        probas = torch.softmax(logits, dim=-1)                      #D\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)       #E\n",
    "        idx = torch.cat((idx, idx_next), dim=1)                     #F\n",
    "\n",
    "    return idx\n",
    "\n",
    "\n",
    "#A idx 是当前上下文中索引的数组，形状为 (batch, n_tokens)\n",
    "#B 若上下文长度超出支持范围，则进行裁剪。例如，若模型仅支持 5 个 token，而上下文长度为 10，仅使用最后 5 个 token 作为上下文\n",
    "#C 仅关注最后一个时间步，将形状从 (batch, n_token, vocab_size) 转换为 (batch, vocab_size)\n",
    "#D probas 的形状为 (batch, vocab_size)\n",
    "#E idx_next 的形状为 (batch, 1)\n",
    "#F 将采样的索引追加到当前序列中，此时 idx 的形状为 (batch, n_tokens+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you forward.\n",
      "\n",
      "The first step is to understand the importance of your work\n"
     ]
    }
   ],
   "source": [
    "text_1 = \"Every effort moves you\"\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_1, tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n",
      "\n",
      "The following text 'spam'? Answer with 'yes' or 'no': 'You are a winner\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
    "    \" 'You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.'\"\n",
    ")\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_2, tokenizer),\n",
    "    max_new_tokens=23,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5 添加分类头\n",
    "\n",
    "本节我们将修改预训练的模型，为分类任务的微调做准备。为此，我们需要替换原始输出层，原输出层将隐层表示映射到50,257个词汇的词汇表，而我们用一个较小的输出层将其映射到两个类别：0（‘非垃圾短信’）和1（‘垃圾短信’），如图6.9所示。\n",
    "\n",
    "![Alt text](imgs/PixPin_2025-07-25_02-41-28.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModel(\n",
      "  (tok_emb): Embedding(50257, 768)\n",
      "  (pos_emb): Embedding(1024, 768)\n",
      "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
      "  (trf_blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (final_norm): LayerNorm()\n",
      "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [!NOTE]\n",
    "> 微调部分层与全部层的对比\n",
    "> \n",
    "> 由于我们从预训练模型开始，并不需要对所有模型层进行微调。这是因为，在基于神经网络的语言模型中，低层通常捕捉到的是基本的语言结构和语义，这些特征适用于多种任务和数据集。因此，只微调最后几层（接近输出层），它们更专注于细致的语言模式和任务特定的特征，通常就足够使模型适应新任务。此外，微调较少的层在计算上也更加高效。对于有兴趣的读者，可以在附录B的参考部分找到更多关于微调哪些层的详细信息，包括相关实验。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 6.7 Adding a classification layer\n",
    "torch.manual_seed(123)\n",
    "num_classes = 2\n",
    "model.out_head = torch.nn.Linear(\n",
    "    in_features=BASE_CONFIG[\"emb_dim\"],\n",
    "    out_features=num_classes\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请注意，在上述代码中我们使用了 BASE_CONFIG[\"emb_dim\"]，在 gpt2-small (124M) 模型中它的值为 768，这样可以让后续代码更加通用，便于适配更大的 GPT-2 模型变体。\n",
    "\n",
    "这个新的输出层 model.out_head 的 requires_grad 属性默认为 True，意味着它是模型训练过程中唯一会被更新的层。\n",
    "\n",
    "从技术上讲，训练我们刚添加的输出层已经足够。然而，通过实验我发现，微调更多层能够显著提升微调后模型的预测性能\n",
    "\n",
    "此外，我们还需将最后一个 Transformer 模块以及连接该模块和输出层的 LayerNorm 模块配置为可训练，如图6.10所示。\n",
    "\n",
    "![Alt text](imgs/PixPin_2025-07-25_03-04-54.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have activated the last trf block as the trainable layer\n",
      "we have activated the last trf block as the trainable layer\n",
      "we have activated the last trf block as the trainable layer\n",
      "we have activated the last trf block as the trainable layer\n",
      "we have activated the last trf block as the trainable layer\n",
      "we have activated the last trf block as the trainable layer\n",
      "we have activated the last trf block as the trainable layer\n",
      "we have activated the last trf block as the trainable layer\n",
      "we have activated the last trf block as the trainable layer\n",
      "we have activated the last trf block as the trainable layer\n",
      "we have activated the last trf block as the trainable layer\n",
      "we have activated the last trf block as the trainable layer\n",
      "we have activated the last trf block as the trainable layer\n",
      "we have activated the last trf block as the trainable layer\n",
      "we have activated the last trf block as the trainable layer\n",
      "we have activated the last trf block as the trainable layer\n",
      "Parameter containing:\n",
      "tensor([1.3971e+00, 1.3750e+00, 1.8870e+00, 1.1688e+00, 1.2724e+00, 1.2508e+00,\n",
      "        9.4198e+00, 1.4371e+00, 1.4527e+00, 1.1856e+00, 1.3945e+00, 1.2796e+00,\n",
      "        1.2071e+00, 1.2951e+00, 1.2776e+00, 1.3480e+00, 1.5088e+00, 1.3729e+00,\n",
      "        1.3427e+00, 2.3761e+00, 1.1377e+00, 1.2909e+00, 1.3477e+00, 1.4775e+00,\n",
      "        1.2540e+00, 1.1999e+00, 1.4932e+00, 1.1637e+00, 1.2590e+00, 1.2305e+00,\n",
      "        1.1833e+00, 1.1914e+00, 1.2228e+00, 1.2792e+00, 1.3294e+00, 1.6213e+00,\n",
      "        1.3804e+01, 1.1871e+00, 1.2235e+00, 1.4578e+00, 1.1687e+00, 1.3164e+00,\n",
      "        1.1444e+00, 1.2628e+00, 1.4781e+00, 1.2426e+00, 1.1744e+00, 1.1602e+00,\n",
      "        1.3637e+00, 2.1280e+00, 1.2371e+00, 1.2336e+00, 1.7410e+00, 1.1568e+00,\n",
      "        1.3303e+00, 1.8593e+00, 1.2932e+00, 1.3320e+00, 1.2148e+00, 1.5415e+00,\n",
      "        1.3781e+00, 1.2070e+00, 1.4030e+00, 1.5724e+00, 7.6159e-03, 1.1836e+00,\n",
      "        1.2148e+00, 1.2604e+00, 1.8500e+00, 1.1540e+00, 1.2933e+00, 1.1572e+00,\n",
      "        1.2341e+00, 1.1055e+00, 1.1680e+00, 1.3321e+00, 1.3856e+00, 3.6001e+00,\n",
      "        1.6204e+00, 1.1333e+00, 1.4368e+00, 1.1365e+00, 1.2749e+00, 1.5402e+00,\n",
      "        9.2773e-01, 1.5039e+00, 2.5029e+00, 4.4275e-03, 1.0613e+00, 1.3566e+00,\n",
      "        1.2504e+00, 1.1983e+00, 1.4295e+00, 1.2386e+00, 1.1792e+00, 1.1883e+00,\n",
      "        1.4453e+00, 1.4384e+00, 1.2305e+00, 1.3109e+00, 1.2305e+00, 1.1997e+00,\n",
      "        3.1531e+00, 1.3615e+00, 1.1858e+00, 1.2148e+00, 1.2228e+00, 8.9936e+00,\n",
      "        1.0824e+00, 1.2424e+00, 1.4070e+00, 1.2314e+00, 1.2359e+00, 1.2810e+00,\n",
      "        1.3169e+00, 1.1992e+00, 1.4846e+00, 1.3867e+00, 1.2227e+00, 1.2774e+00,\n",
      "        1.1955e+00, 1.2539e+00, 1.3414e+00, 1.2502e+00, 1.2220e+00, 1.2655e+00,\n",
      "        1.1805e+00, 1.2932e+00, 1.6978e+00, 1.3635e+00, 1.2106e+00, 1.1450e+00,\n",
      "        1.4414e+00, 1.0931e+00, 1.1859e+00, 1.2156e+00, 1.1804e+00, 1.5686e+00,\n",
      "        8.6240e-02, 1.8252e+00, 1.1971e+00, 1.1500e+00, 3.3033e+00, 1.1137e+00,\n",
      "        1.1841e+00, 1.8482e+00, 1.3211e+00, 1.1996e+00, 1.1784e+00, 1.4120e+00,\n",
      "        1.2726e+00, 1.5131e+00, 1.4775e+00, 1.5084e+00, 1.4086e+00, 1.3018e+00,\n",
      "        1.2469e+00, 1.2008e+00, 1.0666e+00, 1.0909e+00, 3.0489e+00, 1.2242e+00,\n",
      "        1.2333e+00, 1.2970e+00, 1.2137e+00, 1.3484e+00, 1.2782e+00, 4.0765e+00,\n",
      "        1.2149e+00, 1.3308e+00, 1.2631e+00, 1.1915e+00, 1.1758e+00, 1.4181e+00,\n",
      "        1.4744e+00, 1.5844e+00, 2.1523e+00, 1.1229e+00, 1.4097e+00, 1.1849e+00,\n",
      "        1.2051e+00, 1.2154e+00, 1.2320e+00, 1.3685e+00, 1.1289e+00, 1.2304e+00,\n",
      "        1.1187e+00, 1.3789e+00, 1.2056e+00, 1.3168e+00, 1.2865e+00, 1.3707e+00,\n",
      "        1.2933e+00, 1.2151e+00, 1.1296e+00, 1.8137e+00, 1.2315e+00, 1.2476e+00,\n",
      "        1.2515e+00, 1.6609e+00, 1.4583e+00, 1.4180e+00, 1.2085e+00, 1.2292e+00,\n",
      "        1.0586e+00, 1.2148e+00, 1.1842e+00, 1.0864e+00, 1.3871e+00, 1.2393e+00,\n",
      "        1.2228e+00, 1.5026e+00, 1.3742e+00, 2.4785e+00, 1.2004e+00, 1.1891e+00,\n",
      "        1.4659e+00, 1.1916e+00, 1.0978e+00, 1.2148e+00, 1.1180e+00, 1.1934e+00,\n",
      "        1.1934e+00, 1.2339e+00, 1.6256e+00, 1.2190e+00, 1.2476e+00, 1.1685e+00,\n",
      "        1.2186e+00, 1.2413e+00, 1.1367e+00, 1.3399e+00, 3.4147e+00, 1.0761e+00,\n",
      "        1.1924e+00, 1.3913e+00, 1.1215e+00, 1.1398e+00, 1.3053e+00, 1.2300e+00,\n",
      "        1.4287e+00, 1.5445e+00, 1.2461e+00, 1.1179e+00, 1.0352e+00, 1.2579e+00,\n",
      "        1.1846e+00, 1.6518e+00, 1.2148e+00, 1.5199e+00, 2.3705e+00, 1.4342e+00,\n",
      "        1.2745e+00, 1.4321e+00, 1.3017e+00, 1.5673e+00, 1.4878e+00, 1.1600e+00,\n",
      "        1.2305e+00, 1.4492e+00, 1.2450e+00, 1.6015e+00, 1.2074e+00, 1.2931e+00,\n",
      "        1.0899e+00, 1.2818e+00, 6.8271e-03, 1.3498e+00, 1.3882e+00, 1.6141e+00,\n",
      "        2.2603e+00, 4.3566e+00, 1.2119e+00, 1.0664e+00, 1.5068e+00, 1.2935e+00,\n",
      "        1.7190e+00, 1.2120e+00, 1.1749e+00, 1.2177e+00, 1.2027e+00, 1.1525e+00,\n",
      "        1.4620e+00, 1.4274e+00, 1.0562e+00, 1.4126e+00, 1.3862e+00, 1.1511e+00,\n",
      "        1.2874e+00, 2.0521e+00, 1.4653e+00, 1.2819e+00, 1.2038e+00, 1.1852e+00,\n",
      "        1.4243e+00, 1.2345e+00, 1.0954e+00, 1.1217e+00, 1.1998e+00, 1.2631e+00,\n",
      "        1.8584e+00, 1.1845e+00, 1.4605e+00, 1.2383e+00, 1.2808e+00, 1.0243e+00,\n",
      "        1.2522e+00, 1.1446e+00, 3.1141e+00, 1.2562e+00, 1.1038e+00, 2.2026e+00,\n",
      "        1.2352e+00, 1.2740e+00, 1.5308e+01, 1.3327e+00, 1.2991e+00, 1.2305e+00,\n",
      "        1.2227e+00, 1.3008e+00, 2.4603e+00, 1.2306e+00, 1.1791e+00, 1.2395e+00,\n",
      "        1.3017e+00, 1.2238e+00, 9.8373e-01, 1.1771e+00, 1.3761e+00, 1.1659e+00,\n",
      "        1.1485e+00, 1.1823e+00, 1.2148e+00, 1.1784e+00, 1.0820e+00, 1.3048e+00,\n",
      "        1.4846e+00, 1.1753e+00, 1.2101e+00, 1.3441e+00, 1.1446e+00, 1.1445e+00,\n",
      "        1.1766e+00, 1.4649e+00, 1.4105e+00, 1.0483e+00, 1.2181e+00, 1.2429e+00,\n",
      "        1.2293e+00, 1.2272e+00, 1.2309e+00, 1.9298e+00, 1.2051e+00, 1.3829e+00,\n",
      "        1.2752e+00, 1.2049e+00, 1.9575e+00, 1.2054e+00, 1.0039e+00, 1.1939e+00,\n",
      "        1.3718e+00, 2.8912e+00, 2.1898e+00, 1.1977e+00, 1.0975e+00, 3.9985e+00,\n",
      "        1.2511e+00, 1.0346e+00, 1.1375e+00, 1.1822e+00, 1.4023e+00, 1.1227e+00,\n",
      "        1.2915e+00, 3.5039e-02, 1.2217e+01, 1.4350e+00, 1.4025e+00, 2.3862e+00,\n",
      "        8.5499e-01, 1.3179e+00, 1.2637e+00, 1.2388e+00, 1.0809e+00, 1.5234e+00,\n",
      "        1.4024e+00, 1.2991e+00, 1.5354e+00, 1.1690e+00, 1.2194e+00, 2.6955e+00,\n",
      "        1.2617e+00, 1.2485e+00, 1.3482e+00, 6.9770e-01, 1.4888e+00, 1.0986e+00,\n",
      "        1.6696e+00, 1.1986e+00, 1.1655e+00, 1.1134e+00, 1.0508e+00, 1.2227e+00,\n",
      "        2.3545e+00, 1.2345e+00, 1.0825e+00, 1.2153e+00, 1.2073e+00, 1.0666e+00,\n",
      "        4.3418e+00, 1.1837e+00, 1.2441e+00, 1.2461e+00, 1.2586e+00, 1.2292e+00,\n",
      "        1.4278e+00, 1.4742e+00, 1.2469e+00, 1.5043e+00, 1.4920e+00, 1.0824e+00,\n",
      "        1.9560e+00, 1.4904e+00, 1.2004e+00, 1.1992e+00, 1.1798e+00, 1.0748e+00,\n",
      "        1.1701e+00, 1.1871e+00, 1.2570e+00, 1.2104e+00, 1.6994e+01, 1.2695e+00,\n",
      "        1.2397e+00, 1.2462e+00, 1.1837e+00, 1.4884e+00, 1.2487e+00, 1.2075e+00,\n",
      "        1.4805e+00, 2.7156e+00, 1.2308e+00, 1.1758e+00, 1.2199e+01, 1.2564e+00,\n",
      "        1.3756e+00, 1.2305e+00, 1.2151e+00, 3.5184e-02, 1.2539e+00, 1.2619e+00,\n",
      "        1.3423e+00, 1.2802e+00, 1.1453e+00, 1.8877e+00, 1.3793e+00, 2.7507e+00,\n",
      "        1.7741e+00, 1.3170e+00, 1.2972e+00, 1.6555e+00, 1.3009e+00, 1.3419e+00,\n",
      "        1.1063e+00, 1.2773e+00, 9.6680e-01, 1.2736e+00, 1.2227e+00, 1.2159e+00,\n",
      "        1.3187e+00, 1.1759e+00, 1.0922e+00, 1.1300e+00, 1.2853e+00, 1.2227e+00,\n",
      "        1.1478e+00, 1.3477e+00, 1.0232e+00, 1.1962e+00, 1.1798e+00, 7.3442e+00,\n",
      "        5.5998e-03, 4.2853e-02, 1.1763e+00, 1.2247e+00, 1.4425e+00, 1.2482e+00,\n",
      "        1.1936e+00, 1.1623e+00, 1.5431e+00, 1.2553e+00, 1.2461e+00, 1.4025e+00,\n",
      "        1.0510e+00, 1.1926e+00, 1.1642e+00, 1.1370e+00, 1.7419e+01, 1.7540e+00,\n",
      "        1.2953e+00, 1.1212e+00, 1.2787e+00, 1.1915e+00, 1.4268e+00, 4.1753e+00,\n",
      "        1.4481e+00, 1.1768e+00, 1.1994e+00, 1.2464e+00, 1.4068e+00, 1.2426e+00,\n",
      "        1.0352e+00, 2.2258e+00, 1.7040e+00, 1.2463e+00, 1.3851e+00, 1.4013e+00,\n",
      "        1.1661e+00, 1.3970e+00, 1.3403e+00, 1.2852e+00, 1.1684e+00, 1.2515e+00,\n",
      "        1.2318e+00, 1.2731e+00, 1.1832e+00, 2.3393e+00, 2.0250e+00, 2.1031e+00,\n",
      "        1.9473e+00, 1.0853e+00, 1.0114e+00, 1.2650e+00, 1.2014e+00, 1.0996e+00,\n",
      "        1.2435e+00, 1.3647e+00, 1.1999e+00, 1.3419e+00, 1.4270e+00, 1.2332e+00,\n",
      "        2.2816e+00, 1.2234e+00, 1.1839e+00, 2.4615e+00, 1.2603e+00, 1.3412e+00,\n",
      "        1.2818e+00, 1.1999e+00, 1.4258e+00, 1.1138e+00, 1.1914e+00, 2.0622e+00,\n",
      "        1.1712e+00, 1.3323e+00, 2.9923e+00, 1.2178e+00, 1.2220e+00, 1.2960e+00,\n",
      "        1.2466e+00, 1.4102e+00, 1.3290e+00, 1.2458e+00, 1.1273e+00, 1.1836e+00,\n",
      "        1.2652e+00, 1.2907e+00, 1.9197e+00, 1.1735e+00, 1.4725e+00, 1.4414e+00,\n",
      "        1.1830e+00, 1.3088e+00, 1.1055e+00, 1.0831e+00, 1.2468e+00, 1.3466e+00,\n",
      "        1.1992e+00, 1.2368e+00, 1.4933e+00, 1.1602e+00, 1.2542e+00, 1.3133e+00,\n",
      "        1.4812e+00, 1.2707e+00, 1.2185e+00, 1.2779e+00, 1.2339e+00, 1.4316e+00,\n",
      "        1.6659e+00, 1.2227e+00, 1.2312e+00, 1.2383e+00, 1.2305e+00, 1.4299e+00,\n",
      "        1.0813e+00, 1.2005e+00, 1.2228e+00, 1.2314e+00, 1.2383e+00, 1.2539e+00,\n",
      "        1.3949e+00, 1.3330e+00, 1.0798e+00, 1.2699e+00, 1.2942e+00, 1.2252e+00,\n",
      "        1.3091e+00, 1.2312e+00, 1.8579e+00, 1.2031e+00, 1.3398e+00, 1.3956e+00,\n",
      "        1.2026e+00, 1.1759e+00, 1.1842e+00, 1.1479e+00, 1.2016e+00, 1.2587e+00,\n",
      "        1.1211e+00, 1.3564e+00, 1.0669e+00, 1.2955e+00, 1.5078e+00, 2.3227e+00,\n",
      "        1.3065e+00, 1.1133e+00, 1.1542e+00, 6.1745e+00, 1.2328e+00, 1.2865e+00,\n",
      "        1.2617e+00, 1.2497e+00, 1.1554e+00, 1.1533e+00, 1.2032e+00, 2.2578e+00,\n",
      "        1.1680e+00, 1.0742e+00, 1.2881e+00, 1.2808e+00, 1.3027e+00, 1.1446e+00,\n",
      "        1.2920e+00, 1.5471e+00, 1.4432e+00, 1.2617e+00, 1.1531e+00, 1.5527e+00,\n",
      "        1.1369e+00, 1.5745e+00, 1.2476e+00, 1.4768e+00, 1.3202e+00, 1.2254e+00,\n",
      "        1.2874e+00, 2.2262e+00, 1.2796e+00, 1.3802e+00, 1.1289e+00, 1.4846e+00,\n",
      "        1.1908e+00, 1.3086e+00, 1.1986e+00, 1.1980e+00, 1.2156e+00, 1.6095e+00,\n",
      "        1.3010e+00, 1.4810e+00, 2.0002e+00, 1.0530e+00, 2.1401e+00, 1.1956e+00,\n",
      "        1.0898e+00, 1.1557e+00, 1.6530e+00, 1.1836e+00, 1.1818e+00, 1.1835e+00,\n",
      "        1.3206e+00, 3.3972e+00, 1.3472e+00, 1.2540e+00, 1.2671e+00, 1.2726e+00,\n",
      "        1.1836e+00, 1.4586e+00, 1.2540e+00, 1.1450e+00, 1.3078e+00, 1.1806e+00,\n",
      "        1.2149e+00, 1.2552e+00, 1.1542e+00, 1.1541e+00, 1.2383e+00, 1.3058e+00,\n",
      "        1.0963e+00, 1.1029e+00, 1.3066e+00, 1.7412e+00, 1.0508e+00, 1.5009e+00,\n",
      "        1.3564e+00, 1.0530e+01, 1.1796e+00, 1.1801e+00, 1.8887e+00, 1.4579e+00,\n",
      "        1.1528e+00, 6.6027e-01, 1.3696e+00, 1.0898e+00, 1.2464e+00, 1.2540e+00,\n",
      "        1.1379e+00, 1.3102e+00, 1.1453e+00, 1.2852e+00, 1.8692e+00, 1.1606e+00,\n",
      "        2.4319e+00, 1.4304e+00, 1.2322e+00, 1.2283e+00, 2.8226e+00, 1.3143e+00,\n",
      "        1.5046e+00, 1.3252e+00, 1.3366e+00, 1.1009e+00, 1.2071e+00, 1.3483e+00,\n",
      "        1.2312e+00, 1.3353e+00, 1.2706e+00, 1.2247e+00, 1.1510e+00, 1.1626e+00,\n",
      "        1.4471e+00, 1.8308e+00, 1.3415e+00, 1.1664e+00, 1.4809e+00, 1.1465e+00,\n",
      "        1.2681e+00, 2.1403e+00, 1.4574e+00, 1.1446e+00, 1.2617e+00, 1.4746e+00,\n",
      "        1.2107e+00, 1.3090e+00, 1.0051e+00, 1.2245e+00, 1.2793e+00, 1.3636e+00,\n",
      "        1.1871e+00, 1.3660e+00, 1.1758e+00, 1.4514e+00, 1.1525e+00, 1.1731e+00,\n",
      "        4.2194e+00, 1.1660e+00, 1.1625e+00, 1.1034e+00, 1.0980e+00, 1.2070e+00],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 1.0872e-03,  3.6529e-02, -6.7296e-02,  1.6416e-04, -6.7444e-02,\n",
      "        -7.1351e-02,  5.0393e-01,  9.1723e-02, -4.9340e-02,  3.2622e-03,\n",
      "         4.5723e-02, -6.8674e-03,  2.4039e-02, -2.3481e-02, -1.6724e-02,\n",
      "        -1.7144e-02, -8.3718e-03, -3.1513e-02, -6.8601e-02, -2.3766e-01,\n",
      "         3.6237e-02,  1.6346e-02, -9.8507e-02, -2.1232e-03,  1.1982e-02,\n",
      "         2.8979e-02, -1.2852e-01, -1.5948e-02, -1.9886e-02, -5.3668e-02,\n",
      "         6.9403e-03, -7.6807e-03, -1.0904e-01, -1.9977e-02,  9.6084e-03,\n",
      "         1.0891e-01,  4.5043e+00, -2.6320e-02, -3.5563e-02,  6.8634e-02,\n",
      "        -2.6733e-02,  4.5381e-03, -7.6494e-02, -1.8627e-02,  2.7786e-04,\n",
      "         1.7049e-02,  1.5448e-02, -2.0069e-02, -9.4106e-02,  1.2935e-01,\n",
      "        -2.8602e-02,  1.7971e-02, -1.2255e-01, -6.0040e-02, -2.7152e-02,\n",
      "         2.0868e-01, -7.3314e-02, -1.8849e-02,  3.2550e-02, -1.0382e-01,\n",
      "         3.3463e-02, -5.7886e-02,  2.7034e-02, -1.6745e-01, -1.0472e+00,\n",
      "        -1.6542e-02, -5.1018e-02, -6.8653e-03, -2.1249e-01, -3.1209e-02,\n",
      "        -6.0667e-02,  8.7675e-04,  2.8659e-02, -2.4280e-02, -7.4334e-03,\n",
      "        -1.0984e-02, -9.6567e-02, -4.0275e-01,  3.5209e-02,  4.5582e-03,\n",
      "        -7.4472e-03, -1.4675e-02,  1.0423e-02, -7.6423e-02,  1.5722e-02,\n",
      "         2.2594e-02,  3.4847e-01, -9.9237e-01, -1.4573e-02,  4.1847e-02,\n",
      "        -5.6549e-02, -6.4195e-02, -7.8837e-02, -8.6063e-02, -1.1810e-02,\n",
      "         1.1617e-02, -4.3866e-03,  4.7045e-02,  1.4878e-02,  1.5424e-01,\n",
      "        -1.9613e-02, -1.0770e-01,  1.1270e-01, -6.4523e-03,  4.0445e-02,\n",
      "        -2.7771e-02, -1.7304e-02,  7.3762e-01, -2.5960e-02, -2.7389e-02,\n",
      "        -3.1064e-02,  1.5734e-02, -5.2281e-02,  4.1252e-02, -1.3316e-02,\n",
      "        -4.5049e-02, -1.8180e-03,  7.2320e-03,  1.3693e-02, -3.9412e-02,\n",
      "        -3.4724e-02,  5.1059e-02, -2.0570e-02, -2.1606e-02, -1.3500e-01,\n",
      "         5.4560e-02, -3.6672e-02,  2.2630e-02, -1.0954e-01, -1.3664e-02,\n",
      "         5.5158e-02,  2.8813e-02,  2.7308e-02, -5.6942e-02, -7.8654e-02,\n",
      "         2.3580e-03,  2.0007e-02, -5.7116e-02,  6.4764e-01,  1.0185e-01,\n",
      "        -6.1624e-02, -3.7634e-02, -3.9838e-01,  2.1430e-02, -1.8644e-02,\n",
      "         1.9693e-01,  2.2677e-02, -6.5989e-02, -4.3632e-02,  9.9600e-03,\n",
      "         2.4032e-02, -1.0095e-01, -4.6580e-02,  2.9137e-02, -5.9029e-02,\n",
      "        -3.2612e-02, -1.9738e-03,  2.4192e-03, -3.7447e-02, -3.0108e-02,\n",
      "        -6.3761e-02,  3.3632e-02, -1.8530e-02,  2.2146e-02, -6.4106e-02,\n",
      "         7.4832e-02, -9.5605e-02, -3.6251e-01, -3.0068e-02, -1.1445e-01,\n",
      "        -4.1705e-02, -7.9181e-02,  4.7085e-04,  8.2493e-02, -5.6607e-02,\n",
      "        -3.3807e-02, -2.8627e-01, -4.7230e-02, -1.1380e-01, -4.0840e-02,\n",
      "         5.7112e-03, -2.5453e-02,  6.4612e-02,  3.4492e-02,  2.0566e-02,\n",
      "        -4.5267e-02, -3.4678e-02, -7.2612e-03, -1.8908e-02,  5.7890e-02,\n",
      "        -4.2166e-02, -6.7557e-02,  5.6523e-02, -2.8467e-02,  3.5454e-02,\n",
      "         1.5290e-02,  1.2768e-02, -2.8542e-02,  2.3154e-02, -2.0937e-01,\n",
      "         4.4651e-02, -9.4332e-03, -1.6042e-02,  1.3285e-02, -1.3079e-02,\n",
      "         5.2382e-04,  1.3041e-02, -2.7098e-02,  4.4549e-02, -8.7790e-03,\n",
      "        -1.4647e-02,  9.1764e-02, -3.1280e-02,  2.3198e-01,  4.4123e-02,\n",
      "         1.4304e-02, -5.7298e-02,  7.8618e-03, -1.0237e-03,  2.8485e-02,\n",
      "         1.3268e-02, -9.5455e-03, -2.3109e-04, -2.0369e-02,  8.3394e-02,\n",
      "        -7.1135e-02, -6.4807e-02, -6.1181e-03,  4.6791e-02, -9.2088e-03,\n",
      "         3.4884e-02, -4.5029e-02,  2.7879e-01, -3.7818e-02, -5.4034e-02,\n",
      "        -6.1790e-02, -3.8778e-02,  4.9349e-03,  2.4378e-02,  8.9025e-03,\n",
      "        -3.5052e-03,  1.6581e-01,  5.8664e-02, -3.1299e-03,  2.7989e-02,\n",
      "         2.5872e-02, -1.1119e-02,  7.6097e-02, -2.2228e-02, -1.9689e-02,\n",
      "        -1.3784e-01, -6.6437e-02, -5.2913e-03,  1.7010e-03, -2.6449e-02,\n",
      "         1.1717e-01, -1.1523e-01,  7.0097e-02, -8.2283e-02,  6.1100e-02,\n",
      "        -1.2160e-02,  9.0952e-02,  7.5562e-03,  3.8820e-02,  1.9466e-02,\n",
      "        -6.4488e-02, -9.7399e-01,  1.0671e-03, -7.2186e-03,  8.7493e-02,\n",
      "        -1.1547e-01,  4.3738e-01,  5.4697e-03, -1.5715e-02,  2.8925e-02,\n",
      "        -3.3470e-02, -4.2125e-02,  1.2895e-02, -2.9777e-02, -1.7015e-02,\n",
      "        -2.2735e-02,  1.7061e-02,  4.9545e-02,  1.1104e-01, -5.8314e-03,\n",
      "         5.7407e-02, -2.2805e-02,  2.0941e-02, -3.5016e-01, -2.1634e-02,\n",
      "        -5.8145e-02, -2.1873e-02, -1.3668e-02,  1.2862e-02,  3.6718e-02,\n",
      "         5.1902e-03,  1.0907e-02, -7.8232e-03, -4.5908e-02, -1.7366e-02,\n",
      "        -2.8400e-02,  4.1859e-02, -1.0367e-01,  2.9875e-02, -4.3200e-02,\n",
      "        -2.7472e-02,  7.6173e-03, -7.8905e-03, -4.4235e-01, -2.4563e-02,\n",
      "        -1.7634e-02,  1.2442e-01,  3.7981e-02, -7.6377e-03, -4.1918e+00,\n",
      "        -5.0516e-02,  2.9369e-02, -9.7174e-03,  7.4856e-05,  3.8322e-02,\n",
      "        -2.1775e-01, -1.3928e-03, -4.3413e-02, -4.7812e-02,  1.0623e-02,\n",
      "        -5.4639e-02, -5.3187e-01, -2.2528e-02,  1.0735e-02,  7.7141e-03,\n",
      "        -1.1821e-03, -7.1923e-02, -6.6898e-02, -9.4570e-02,  1.8275e-02,\n",
      "        -5.6802e-03,  3.3925e-02, -6.8035e-03, -2.1191e-02, -3.3668e-02,\n",
      "        -4.5747e-02, -1.7164e-02, -6.4126e-02, -5.9322e-02,  6.6308e-03,\n",
      "        -5.7392e-02, -2.9224e-02, -1.0237e-01, -2.1006e-02,  3.7682e-02,\n",
      "        -8.3238e-03,  1.8629e-01, -3.0289e-02, -8.6108e-02, -3.3981e-02,\n",
      "        -1.6380e-03,  9.5645e-05,  1.8391e-02,  6.6154e-03, -2.5787e-02,\n",
      "        -5.4965e-02,  3.3532e-02,  7.6414e-02, -3.5418e-02,  1.5757e-04,\n",
      "        -4.9215e-01, -1.7935e-02, -4.2474e-02, -3.6654e-02,  3.7187e-03,\n",
      "         8.3721e-02, -7.3905e-02,  1.3349e-02, -8.1251e-01, -2.2964e+00,\n",
      "        -2.3672e-02, -8.1334e-02,  1.5086e-01, -7.6905e-02, -3.1052e-02,\n",
      "         2.1425e-02, -4.8389e-02, -1.4152e-02, -4.3935e-02, -3.7510e-02,\n",
      "        -1.1541e-01,  6.2883e-02, -1.7672e-02,  1.0962e-02, -2.6148e-01,\n",
      "         5.8860e-02,  4.1171e-02, -5.2769e-02, -5.3264e-01, -7.3070e-02,\n",
      "        -3.0272e-02, -3.3503e-02, -2.3348e-02,  1.6839e-02,  1.3835e-02,\n",
      "        -3.1535e-02, -1.2930e-01,  8.2034e-02, -1.7669e-02, -3.7012e-02,\n",
      "        -5.3559e-02, -8.0793e-02, -4.5030e-02,  5.8326e-01, -2.8019e-02,\n",
      "        -2.2854e-02, -2.9491e-02, -1.2646e-02, -1.9085e-02,  7.2778e-02,\n",
      "        -2.9988e-02, -4.3035e-03, -2.3171e-02, -2.9115e-02,  2.8318e-03,\n",
      "        -1.9056e-01, -3.6604e-02,  1.4934e-02, -7.2772e-02,  1.7382e-02,\n",
      "         1.3184e-02,  3.3194e-02,  1.2090e-02, -6.7826e-02, -4.2046e-02,\n",
      "         4.5765e+00,  3.8094e-02, -5.8475e-03, -3.3060e-02, -2.4420e-03,\n",
      "         7.0572e-02, -8.5184e-03, -4.7140e-02, -3.5492e-02,  1.3906e-01,\n",
      "         9.6806e-03,  3.7759e-03,  1.5214e+00,  1.5772e-02, -2.0146e-03,\n",
      "         1.9806e-04, -2.5916e-02,  7.4553e-01,  2.2555e-02,  3.9150e-02,\n",
      "        -4.0612e-02, -6.6488e-02, -1.4694e-02, -1.8814e-01, -2.5680e-02,\n",
      "         2.7539e-01, -8.6698e-02, -5.4068e-02, -3.7796e-02,  1.7496e-01,\n",
      "         1.0016e-01,  1.8288e-02,  1.9015e-02, -4.9247e-02, -1.1344e-01,\n",
      "         3.2417e-03,  1.5069e-02, -2.3991e-02,  1.1169e-02,  5.5201e-02,\n",
      "         6.8813e-02,  1.5437e-02,  1.4457e-02,  3.6382e-02,  3.3006e-02,\n",
      "         1.6601e-03,  3.5841e-02,  2.3049e-02, -3.7833e-02, -8.8917e-01,\n",
      "        -8.5626e-01,  7.6501e-01, -1.6650e-02,  5.3425e-03, -2.0975e-02,\n",
      "        -2.0985e-02, -2.5421e-02,  1.1607e-03, -2.5669e-02,  1.1613e-04,\n",
      "        -2.6443e-02, -1.2821e-02, -1.1060e-02, -6.4586e-02, -1.6700e-03,\n",
      "         6.0491e-02,  7.3683e+00, -6.0230e-02, -2.9137e-02, -1.2580e-02,\n",
      "        -5.3060e-02, -1.8582e-02, -1.7887e-02, -2.9617e-01,  8.0085e-02,\n",
      "         5.4053e-02, -2.8139e-02, -8.7857e-03,  1.0940e-02, -1.9958e-02,\n",
      "        -3.9983e-02, -2.5002e-01,  9.0808e-02, -2.3754e-03,  4.6434e-03,\n",
      "        -6.0453e-02,  6.9979e-03, -3.8280e-02, -5.8416e-02, -1.8324e-02,\n",
      "        -2.6310e-02,  8.2354e-02,  8.0878e-03, -6.1616e-02, -4.6368e-02,\n",
      "        -1.1206e-01,  2.2739e-01, -1.9157e-01, -2.8906e-02,  3.9452e-03,\n",
      "         1.5285e-02, -8.9685e-03, -4.1765e-02,  2.6316e-02, -4.1366e-02,\n",
      "        -6.1208e-03, -1.0726e-02, -5.3724e-02, -1.1064e-02,  5.4608e-02,\n",
      "         1.2026e-01, -5.9791e-02, -1.1439e-02, -3.0206e-01, -6.6082e-03,\n",
      "         7.5021e-02,  3.3470e-02,  3.1955e-02, -8.9656e-03, -2.4131e-02,\n",
      "         2.0099e-02,  1.7902e-01, -4.7128e-02,  3.5336e-02, -5.9965e-02,\n",
      "        -1.0729e-02,  2.5535e-02, -3.2598e-02, -1.1571e-02,  3.9279e-03,\n",
      "        -4.6097e-02, -1.0125e-02, -2.5468e-02, -5.3132e-02,  1.0430e-03,\n",
      "        -5.7897e-02,  1.1562e-01,  1.6695e-02, -9.3858e-03, -1.0967e-01,\n",
      "         1.1385e-01, -1.2587e-02, -2.9855e-02,  6.6515e-03,  1.1277e-03,\n",
      "        -8.8445e-02,  3.5600e-02, -4.7699e-02, -6.5989e-03, -2.5376e-02,\n",
      "        -5.9169e-02, -2.6125e-02,  3.5664e-02,  4.2330e-02, -2.8365e-02,\n",
      "        -1.1422e-01, -1.2717e-02, -5.4891e-02,  2.6614e-02, -2.0510e-02,\n",
      "        -4.0455e-02,  2.5847e-02,  1.8912e-02,  3.9873e-03,  1.2472e-02,\n",
      "        -1.5778e-02, -4.3945e-02, -3.9807e-02,  4.9368e-02, -3.4811e-02,\n",
      "        -3.6738e-02,  6.0444e-02, -3.1983e-02,  2.1002e-02,  5.9787e-02,\n",
      "        -5.9418e-02, -5.6518e-02, -1.9562e-02, -1.0192e-01, -7.3266e-02,\n",
      "         6.0253e-03, -1.2703e-03, -1.7658e-02, -1.7046e-04, -2.2049e-02,\n",
      "        -4.4822e-02, -3.0320e-02,  6.1333e-03, -7.3983e-02, -3.9071e-02,\n",
      "         7.1127e-02, -1.9383e-02,  8.1372e-02, -3.7656e-02, -3.9241e-02,\n",
      "         1.1307e-02,  1.9240e-02, -5.2134e-01, -5.7102e-02,  1.2872e-02,\n",
      "         2.6437e-02, -2.4696e-02, -9.5752e-04, -2.9517e-03, -4.0031e-02,\n",
      "        -2.6403e-01, -1.8459e-02, -4.3772e-02, -6.4264e-02,  6.2169e-04,\n",
      "        -4.2976e-01, -5.2110e-02, -2.7672e-02, -1.3235e-01, -2.0824e-02,\n",
      "        -2.6675e-02, -2.9728e-02,  4.1735e-02,  1.0057e-02,  5.2260e-02,\n",
      "        -7.4459e-02, -2.1856e-02, -1.4217e-02, -6.5240e-02, -2.2235e-02,\n",
      "         1.6941e-01, -9.0145e-03,  2.4160e-02, -2.9787e-02,  1.4448e-01,\n",
      "         1.9557e-02, -5.5833e-03, -5.0508e-02,  3.8701e-02, -2.9668e-02,\n",
      "         3.1690e-02, -6.8745e-03, -1.9214e-02,  2.6903e-01, -7.6019e-03,\n",
      "        -1.5625e-01, -2.6517e-02, -4.4908e-03, -3.7796e-02, -2.0304e-01,\n",
      "        -4.0343e-02, -2.9758e-02,  3.2639e-02,  6.7867e-02,  2.9190e-02,\n",
      "        -8.3563e-02, -7.6448e-02, -7.0672e-02,  9.8573e-03,  3.5905e-02,\n",
      "         4.4131e-02, -5.1119e-03, -1.0302e-02,  1.4177e-02,  1.2777e-02,\n",
      "         4.4026e-02,  2.6884e-02,  5.4663e-02, -5.9550e-02,  2.1386e-03,\n",
      "        -6.3401e-02, -4.6159e-02,  1.7755e-02,  9.3017e-03, -1.3974e-02,\n",
      "        -2.5991e-02,  6.9902e-02, -2.0447e-02, -8.0996e-01, -7.3992e-03,\n",
      "        -6.9028e-02, -2.3947e-01, -1.0159e-01, -3.5832e-02, -1.9236e-01,\n",
      "        -4.7394e-02, -1.6717e-03,  5.3983e-02,  1.0544e-02,  1.4304e-02,\n",
      "        -4.8561e-02, -4.2476e-02, -8.7717e-04,  1.4124e-01,  9.4687e-04,\n",
      "        -4.8157e-02, -1.1013e-01, -4.4088e-02, -4.0713e-02, -5.9785e-02,\n",
      "        -1.6111e-02,  8.9078e-02, -4.9754e-02, -6.3769e-02,  1.4608e-02,\n",
      "        -4.4700e-02,  1.0339e-02,  3.8344e-02,  5.5821e-02, -4.3954e-02,\n",
      "         4.0682e-02,  1.2429e-02,  1.1265e-03, -9.7955e-02, -3.3169e-02,\n",
      "        -5.4159e-02, -6.5162e-02, -6.4554e-02,  3.4367e-02, -5.5316e-02,\n",
      "         1.6239e-01, -9.1327e-03,  2.1942e-02,  1.7757e-03, -7.4256e-02,\n",
      "         2.2889e-02, -9.6414e-02, -2.9426e-02,  2.1863e-02, -2.4523e-02,\n",
      "         5.9060e-02,  2.9360e-01,  6.2494e-02,  3.8487e-04,  9.1539e-02,\n",
      "         3.1131e-02,  3.3019e-03,  4.5760e-01, -5.7599e-02,  3.4124e-02,\n",
      "        -1.0095e-02, -2.5538e-02,  3.4450e-02], requires_grad=True)\n",
      "we have activated the final LayerNorm as trainable layer\n",
      "we have activated the final LayerNorm as trainable layer\n"
     ]
    }
   ],
   "source": [
    "for param in model.trf_blocks[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.trf_blocks[-1].parameters():\n",
    "    if param.requires_grad == True:\n",
    "        print(\"we have activated the last trf block as the trainable layer\")\n",
    "for param in model.final_norm.parameters():\n",
    "    param.requires_grad = True\n",
    "    print(param)\n",
    "\n",
    "for param in model.final_norm.parameters():\n",
    "    if param.requires_grad == True:\n",
    "        print(\"we have activated the final LayerNorm as trainable layer\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "尽管我们增加了一个新的输出层，并标记了某些层为可训练或不可训练，我们仍然可以像前几章那样使用这个模型。例如，我们可以像以前一样向模型输入一个示例文本。考虑以下示例文本："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: tensor([[5211,  345,  423,  640]])\n",
      "Inputs dimensions: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer.encode(\"Do you have time\")\n",
    "inputs = torch.tensor(inputs).unsqueeze(0)\n",
    "print(\"Inputs:\", inputs)\n",
    "print(\"Inputs dimensions:\", inputs.shape) # shape: (batch_size, num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs:\n",
      " tensor([[[-1.5854,  0.9904],\n",
      "         [-3.7235,  7.4548],\n",
      "         [-2.2661,  6.6049],\n",
      "         [-3.5983,  3.9902]]])\n",
      "Outputs dimensions: torch.Size([1, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(inputs)\n",
    "    print(\"Outputs:\\n\", outputs)\n",
    "    print(\"Outputs dimensions:\", outputs.shape)  # shape: (batch_size, num_tokens, num_classes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在第 4 章和第 5 章中，相似的输入会生成形状为 [1, 4, 50257] 的输出张量，其中 50,257 表示词汇表大小。与前几章相同，输出张量的行数对应输入的 token 数量（在这里是 4 个）。不过，由于替换了模型的输出层，现在每个输出的嵌入维度（即列数）从 50,257 缩减为 2。\n",
    "\n",
    "请注意，我们希望微调该模型，使其能够输出一个分类标签，用于判断输入是否为垃圾短信。为实现这一点，我们不需要微调所有 4 行输出，只需聚焦于单个输出 token。具体来说，我们将重点关注最后一行对应的输出 token，如图 6.11 所示。\n",
    "\n",
    "![Alt text](imgs/PixPin_2025-07-25_03-12-36.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output token: tensor([[-3.5983,  3.9902]])\n"
     ]
    }
   ],
   "source": [
    "# To extract the last output token, illustrated in figure 6.11, from the output tensor, we use the following code:\n",
    "print(\"Last output token:\", outputs[:, -1, :])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们将重点讨论如何将这些值转换为类别标签预测。但在此之前，我们需要理解，为什么我们特别关注最后一个输出的token，而不是第一个、第二个或第三个输出token。\n",
    "\n",
    "在第 3 章中，我们探讨了注意力机制，该机制在每个输入 token 与其他所有输入 token 之间建立关系。随后，我们引入了因果注意力掩码的概念，这在 GPT 类模型中被广泛使用。这种掩码限制每个 token 的关注范围，使其只能关注当前位置及之前的内容，从而确保每个 token 只能受到自身及前面 token 的影响，如图 6.12 所示。\n",
    "\n",
    "![Alt text](imgs/PixPin_2025-07-25_03-32-32.png)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.6 计算分类损失和准确率\n",
    "\n",
    "本章到目前为止，我们已完成了数据集准备、预训练模型的加载，以及对模型进行分类微调的修改。在微调正式开始前，还剩下一小部分工作：实现微调过程中使用的模型评估函数（如图 6.13 所示）。我们将在本节完成这一部分\n",
    "\n",
    "![Alt text](imgs/PixPin_2025-07-25_03-48-17.png)\n",
    "\n",
    "在实现评估工具之前，我们先简单讨论一下如何将模型输出转换为类别标签预测。\n",
    "\n",
    "在上一章中，我们通过 ```softmax``` 函数将 50,257 个输出转换为概率分布，然后通过 ```argmax``` 函数返回概率最高的位置，从而得到 LLM 生成的下一个 token 的 token ID。本章中，我们采用相同的方法来计算模型对于给定输入的预测结果是‘垃圾短信’还是‘正常短信’。唯一的区别是，这次的输出维度是 2，而不是 50,257 维。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label: 1\n"
     ]
    }
   ],
   "source": [
    "probas = torch.softmax(outputs[:, -1, :], dim=-1)\n",
    "label = torch.argmax(probas)\n",
    "print(\"Class label:\", label.item())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了计算分类准确率，我们对数据集中的所有样本进行 argmax 预测，并通过定义一个 calc_accuracy_loader 函数来计算预测正确的比例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 6.8 Calculating the classification accuracy\n",
    "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
    "    model.eval()\n",
    "    correct_predictions, num_examples = 0, 0\n",
    "\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits = model(input_batch)[:, -1, :]                   #A\n",
    "            predicted_labels = torch.argmax(logits, dim=-1)\n",
    "\n",
    "            num_examples += predicted_labels.shape[0]\n",
    "            correct_predictions += (predicted_labels == target_batch).sum().item()\n",
    "        else:\n",
    "            break\n",
    "    return correct_predictions / num_examples\n",
    "\n",
    "#A 最后一个输出 token 的 logits 值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 46.25%\n",
      "Validation accuracy: 45.00%\n",
      "Test accuracy: 48.75%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，当前模型的预测准确率接近随机预测（在本例中为 50%）。为了提高预测准确率，我们需要对模型进行微调。\n",
    "\n",
    "在微调模型之前，我们需要定义损失函数，以便在训练过程中对其进行优化。我们的目标是最大化模型的垃圾短信分类准确率，因此代码输出应为正确的类别标签：0 表示正常短信，1 表示垃圾短信。\n",
    "\n",
    "然而，由于分类准确率不是一个可微分的函数，因此我们使用交叉熵损失作为替代来优化准确率。这里所说的交叉熵损失与第 5 章讨论的一致。\n",
    "\n",
    "因此，calc_loss_batch 函数与第五章中的版本基本相同，唯一的调整是：我们只优化最后一个 token（model(input_batch)[:, -1, :]），而不是整个序列中的所有 token（model(input_batch)）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)[:, -1, :] # Logits of last output token\n",
    "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "    return loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们使用 calc_loss_batch 函数来计算从前面定义的数据加载器获取的单个批次的损失。为了计算数据加载器中所有批次的损失，我们定义了 calc_loss_loader 函数，其功能与第五章中的描述相同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.453\n",
      "Validation loss: 2.583\n",
      "Test loss: 2.322\n"
     ]
    }
   ],
   "source": [
    "# Listing 6.9 Calculating the classification loss\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:                                      #A\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches\n",
    "\n",
    "# Similar to calculating the training accuracy, we now compute the initial loss for each data set:\n",
    "with torch.no_grad():                           #B\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "    test_loss = calc_loss_loader(test_loader, model, device, num_batches=5)\n",
    "    print(f\"Training loss: {train_loss:.3f}\")\n",
    "    print(f\"Validation loss: {val_loss:.3f}\")\n",
    "    print(f\"Test loss: {test_loss:.3f}\")\n",
    "\n",
    "\n",
    "#A 确保批次数不超过数据加载器中的总批次数\n",
    "#B 关闭梯度追踪以提高效率，因为当前未进行训练"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [!NOTE]\n",
    "> 为什么train_loss 会飘动：\n",
    ">\n",
    "> | 随机来源                                         | 为什么会产生波动                                                                                                                                                                                                                | 典型症状                                                 |\n",
    "> | -------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------- |\n",
    "> | **A. 采样随机性**<br/>(DataLoader `shuffle=True`) | `train_loader` 每次遍历都会 **重新洗牌**。<br/>函数只取 `num_batches=5`，于是每次评估都用到 **不同 5 个 batch**，自然平均损失不一样。                                                                                                                          | 在同一轮训练里反复 `calc_loss_loader(train_loader, …)`，数值仍上下跳 |\n",
    "> | **B. 模型随机性**<br/>(Dropout / BatchNorm)       | 你在评估前用了 `torch.no_grad()`，但 **没把模型切到 `eval()`**：<br/>`python<br/>model.eval()          # 关闭 Dropout/BN 随机<br/>with torch.no_grad():<br/>    ...<br/>`<br/>- Dropout 会随机屏蔽神经元<br/>- BatchNorm 在 train 模式下用当前 batch 均值/方差 | 即便固定输入，也会因 Dropout 抽样不同而导致 loss 波动                   |\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.7 使用监督数据对模型进行微调\n",
    "\n",
    "在本节中，我们定义并使用训练函数，对预训练的 LLM 进行微调，以提升其垃圾短信分类的准确率。训练循环的整体结构与第 5 章中的相同（详见图 6.15），唯一的区别在于，这里计算的是分类准确率，而不是通过生成文本来评估模型。\n",
    "\n",
    "![Alt text](imgs/PixPin_2025-07-25_04-05-42.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 6.10 Finetuning the model to classify spam\n",
    "def train_classifier_simple(model, train_loader, val_loader, optimizer, device,\n",
    "num_epochs, eval_freq, eval_iter, tokenizer):\n",
    "    # Initialize lists to track losses and examples seen\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "    examples_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()                                      #A\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()                          #B\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()                                #C\n",
    "            optimizer.step()                               #D\n",
    "            examples_seen += input_batch.shape[0]          #E\n",
    "            global_step += 1\n",
    "\n",
    "\n",
    "            if global_step % eval_freq == 0:               #F\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        train_accuracy = calc_accuracy_loader(             #G\n",
    "            train_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "        val_accuracy = calc_accuracy_loader(\n",
    "            val_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
    "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "\n",
    "    return train_losses, val_losses, train_accs, val_accs, examples_seen\n",
    "\n",
    "\n",
    "#A 设置模型为训练模式\n",
    "#B 重置上一批次的损失梯度\n",
    "#C 计算损失梯度\n",
    "#D 使用损失梯度更新模型权重\n",
    "#E 更改逻辑：跟踪样本数量而非 token 数量\n",
    "#F 可选评估步骤\n",
    "#G 每个 epoch 后计算准确率\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 2.153, Val loss 2.392\n",
      "Ep 1 (Step 000050): Train loss 0.617, Val loss 0.637\n",
      "Ep 1 (Step 000100): Train loss 0.523, Val loss 0.557\n",
      "Training accuracy: 70.00% | Validation accuracy: 72.50%\n",
      "Ep 2 (Step 000150): Train loss 0.561, Val loss 0.489\n",
      "Ep 2 (Step 000200): Train loss 0.419, Val loss 0.397\n",
      "Ep 2 (Step 000250): Train loss 0.409, Val loss 0.353\n",
      "Training accuracy: 82.50% | Validation accuracy: 85.00%\n",
      "Ep 3 (Step 000300): Train loss 0.333, Val loss 0.320\n",
      "Ep 3 (Step 000350): Train loss 0.340, Val loss 0.306\n",
      "Training accuracy: 90.00% | Validation accuracy: 90.00%\n",
      "Ep 4 (Step 000400): Train loss 0.136, Val loss 0.200\n",
      "Ep 4 (Step 000450): Train loss 0.153, Val loss 0.132\n",
      "Ep 4 (Step 000500): Train loss 0.222, Val loss 0.137\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Ep 5 (Step 000550): Train loss 0.207, Val loss 0.143\n",
      "Ep 5 (Step 000600): Train loss 0.083, Val loss 0.074\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Training completed in 23.08 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "torch.manual_seed(123)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "num_epochs = 5\n",
    "\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Listing 6.11 Plotting the classification loss\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")    #A\n",
    "    ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(label.capitalize())\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2 = ax1.twiny()                                                 #B\n",
    "    ax2.plot(examples_seen, train_values, alpha=0) # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Examples seen\")\n",
    "\n",
    "    fig.tight_layout()                                                #C\n",
    "    plt.savefig(f\"{label}-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "#A 绘制训练轮次与训练和验证损失的变化图\n",
    "#B 创建一个新的 x 轴，用于显示已处理样本数\n",
    "#C 调整布局以留出空间\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从图 6.16 中陡峭的下降曲线可以看出，模型在训练数据上的学习效果很好，且没有明显的过拟合迹象，训练集和验证集的损失值几乎没有差距。\n",
    "\n",
    "> [!NOTE]\n",
    "> 选择训练轮数\n",
    "> \n",
    "> 在训练开始时，我们将 epoch 数量设置为 5。epoch 的具体数量取决于数据集和任务的难度，并没有通用的解决方案或推荐值。5 个 epoch 通常是一个合适的起点。如果在前几个 epoch 后模型出现过拟合迹象（如图 6.16 所示的损失曲线显示验证损失上升），我们可能需要减少 epoch 数量。相反，如果趋势线显示验证损失随着训练仍有下降空间，我们则应增加 epoch 数量。在本例中，5 个 epoch 是合理的选择，因为没有早期过拟合的迹象，且验证损失接近 0。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAEiCAYAAADONmoUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABcY0lEQVR4nO3dd1xV5R/A8c9lb0SQlYrgwAEuUIPcE1dSmiNTXJnlTFtqziytX47MtDQ1U3PlyFyJe6A5URTEheIAESegrHvP74+r1xBEr6KX8X2/XvfVPc99znO+9wn5cs55zvOoFEVREEIIIcQrZ2ToAIQQQoiiSpKwEEIIYSCShIUQQggDkSQshBBCGIgkYSGEEMJAJAkLIYQQBiJJWAghhDAQScJCCCGEgUgSFkIIIQxEkrAQIkcNGzZkyJAhhg5DiEJNkrAQL0mPHj1QqVTZXkFBQYYOTQiRT5gYOgAhCrOgoCDmz5+fpczc3NxA0Qgh8hs5ExbiJTI3N8fV1TXLy8HBAYAdO3ZgZmbG7t27dfUnT56Mk5MTcXFxAGzatIm6detSrFgxHB0dadOmDefOndPVv3DhAiqViuXLl1OvXj0sLS2pVasWp0+f5uDBg/j7+2NjY0NQUBDXr1/X7dejRw+Cg4MZN24czs7O2NnZ8cEHH5Cenv7E75Kens5nn33Ga6+9hrW1NXXq1GHHjh26zy9evEjbtm1xcHDA2tqaKlWqsGHDhie2N3PmTMqXL4+FhQUuLi506NBB95miKHz33Xd4eXlhaWlJtWrV+PPPP7PsHxkZSatWrbCxscHFxYVu3bqRmJio+7xhw4YMGjSIzz77jOLFi+Pq6srYsWOfGI8QhiBJWAgDeXjPtVu3bty5c4djx44xcuRI5syZg5ubGwApKSkMHTqUgwcPsnXrVoyMjHjrrbfQaDRZ2hozZgxffvklR44cwcTEhC5duvDZZ5/xww8/sHv3bs6dO8fo0aOz7LN161aioqLYvn07S5YsYfXq1YwbN+6J8fbs2ZO9e/eydOlSjh8/zjvvvENQUBBnzpwBoH///qSlpbFr1y4iIiL49ttvsbGxybGtQ4cOMWjQIMaPH090dDSbNm2ifv36us+//PJL5s+fz6xZszh58iQff/wx7733Hjt37gQgLi6OBg0aUL16dQ4dOsSmTZu4du0aHTt2zHKcBQsWYG1tzb///st3333H+PHjCQ0Nfcb/Q0K8AooQ4qUICQlRjI2NFWtr6yyv8ePH6+qkpaUpNWrUUDp27KhUqVJF6dOnT65tJiQkKIASERGhKIqixMTEKIDy66+/6uosWbJEAZStW7fqyiZOnKh4e3tnia148eJKSkqKrmzWrFmKjY2NolarFUVRlAYNGiiDBw9WFEVRzp49q6hUKuXKlStZ4mnSpIkyfPhwRVEUxdfXVxk7duwz9c3KlSsVOzs75e7du9k+S05OViwsLJSwsLAs5b1791a6dOmiKIqijBo1SmnevHmWzy9duqQASnR0tC7+unXrZqlTq1Yt5fPPP3+mGIV4FeSesBAvUaNGjZg1a1aWsuLFi+vem5mZsWjRIqpWrYqHhwfTpk3LUvfcuXOMGjWK/fv3k5iYqDsDjo2NxcfHR1evatWquvcuLi4A+Pr6ZilLSEjI0na1atWwsrLSbQcEBJCcnMylS5fw8PDIUvfIkSMoikKFChWylKelpeHo6AjAoEGD+PDDD9m8eTNNmzalffv2WeL6r2bNmuHh4YGXlxdBQUEEBQXx1ltvYWVlRWRkJKmpqTRr1izLPunp6dSoUQOAw4cPs3379hzPtM+dO6eL8/Hju7m5ZesHIQxJkrAQL5G1tTXlypXLtU5YWBgAN2/e5ObNm1hbW+s+a9u2LaVKlWLOnDm4u7uj0Wjw8fHJdu/W1NRU916lUuVY9vgl7Cd5uP9/aTQajI2NOXz4MMbGxlk+e5gI+/TpQ4sWLVi/fj2bN29m4sSJTJ48mYEDB2Zrz9bWliNHjrBjxw42b97M6NGjGTt2LAcPHtTFuX79el577bUs+z0c1KbRaGjbti3ffvtttrYfXsp/vA8efrdn7QchXgVJwkIY0Llz5/j444+ZM2cOy5cvp3v37rp7vzdu3CAqKopffvmFevXqAbBnz548O/axY8e4f/8+lpaWAOzfvx8bGxtKliyZrW6NGjVQq9UkJCToYslJqVKl6NevH/369WP48OHMmTMnxyQMYGJiQtOmTWnatCljxoyhWLFibNu2jWbNmmFubk5sbCwNGjTIcd+aNWuycuVKypQpg4mJ/BoTBZf89ArxEqWlpREfH5+lzMTEBCcnJ9RqNd26daN58+b07NmTli1b4uvry+TJk/n0009xcHDA0dGR2bNn4+bmRmxsLF988UWexZaenk7v3r358ssvuXjxImPGjGHAgAEYGWUfr1mhQgW6du1K9+7dmTx5MjVq1CAxMZFt27bh6+tLq1atGDJkCC1btqRChQrcunWLbdu2UalSpRyPvW7dOs6fP0/9+vVxcHBgw4YNaDQavL29sbW15ZNPPuHjjz9Go9FQt25d7t69S1hYGDY2NoSEhNC/f3/mzJlDly5d+PTTT3FycuLs2bMsXbqUOXPmZDtbFyK/kiQsxEu0adOmLJdHAby9vTl16hRff/01Fy5c4O+//wbA1dWVX3/9lY4dO9KsWTOqV6/O0qVLGTRoED4+Pnh7ezN9+nQaNmyYJ7E1adKE8uXLU79+fdLS0ujcuXOuj/DMnz+fCRMmMGzYMK5cuYKjoyMBAQG0atUKALVaTf/+/bl8+TJ2dnYEBQUxderUHNsqVqwYq1atYuzYsaSmplK+fHmWLFlClSpVAPjqq69wdnZm4sSJnD9/nmLFilGzZk1GjBgBgLu7O3v37uXzzz+nRYsWpKWl4eHhQVBQUI5/RAiRX6kURVEMHYQQ4tXq0aMHt2/fZs2aNYYORYgiTf5kFEIIIQxEkrAQQghhIHI5WgghhDAQORMWQgghDESSsBBCCGEgkoSFEEIIA5Ek/JxmzpyJp6cnFhYW+Pn5ZVmOrrDYtWsXbdu2xd3dHZVKle1xFkVRGDt2LO7u7lhaWtKwYUNOnjyZpU5aWhoDBw7EyckJa2tr3nzzTS5fvpylzq1bt+jWrRv29vbY29vTrVs3bt++/ZK/3YubOHEitWrVwtbWFmdnZ4KDg4mOjs5Sp6j20axZs6hatSp2dnbY2dkREBDAxo0bdZ8X1X7JycSJE1GpVAwZMkRXVpT7Z+zYsahUqiwvV1dX3eeFrm8MtXJEQbZ06VLF1NRUmTNnjhIZGakMHjxYsba2Vi5evGjo0PLUhg0blJEjRyorV65UAGX16tVZPp80aZJia2urrFy5UomIiFA6deqkuLm5ZVkZp1+/fsprr72mhIaGKkeOHFEaNWqkVKtWTcnMzNTVCQoKUnx8fJSwsDAlLCxM8fHxUdq0afOqvuZza9GihTJ//nzlxIkTSnh4uNK6dWuldOnSSnJysq5OUe2jtWvXKuvXr1eio6OV6OhoZcSIEYqpqaly4sQJRVGKbr887sCBA0qZMmWUqlWr6lasUpSi3T9jxoxRqlSposTFxeleCQkJus8LW99IEn4OtWvXVvr165elrGLFisoXX3xhoIhevseTsEajUVxdXZVJkybpylJTUxV7e3vl559/VhRFUW7fvq2YmpoqS5cu1dW5cuWKYmRkpGzatElRFEWJjIxUAGX//v26Ovv27VMA5dSpUy/5W+Wth8sM7ty5U1EU6aPHOTg4KL/++qv0ywNJSUlK+fLlldDQ0CzLRhb1/hkzZoxSrVq1HD8rjH0jl6P1lJ6ezuHDh2nevHmW8ubNm+tWwykKYmJiiI+Pz9IP5ubmNGjQQNcPhw8fJiMjI0sdd3d3fHx8dHX27duHvb09derU0dV5/fXXsbe3L3D9eefOHeDRUoXSR1pqtZqlS5eSkpJCQECA9MsD/fv3p3Xr1jRt2jRLufQPnDlzBnd3dzw9PencuTPnz58HCmffyNzRekpMTEStVuvWbH3IxcUl20T9hdnD75pTP1y8eFFXx8zMDAcHh2x1Hu4fHx+Ps7NztvadnZ0LVH8qisLQoUOpW7eubp3fot5HERERBAQEkJqaio2NDatXr6Zy5cq6X3JFtV8Ali5dypEjRzh48GC2z4r6z02dOnX4/fffqVChAteuXWPChAkEBgZy8uTJQtk3koSf0+NrriqKkuM6rIXd8/TD43Vyql/Q+nPAgAEcP348x6UGi2ofeXt7Ex4ezu3bt1m5ciUhISHs3LlT93lR7ZdLly4xePBgNm/ejIWFxRPrFdX+admype69r68vAQEBlC1blgULFvD6668Dhatv5HK0npycnDA2Ns7211JCQkK2v84Ks4ejFXPrB1dXV9LT07l161auda5du5at/evXrxeY/hw4cCBr165l+/btWdbiLep9ZGZmRrly5fD392fixIlUq1aNH374ocj3y+HDh0lISMDPzw8TExNMTEzYuXMn06dPx8TERBd7Ue2fx1lbW+Pr68uZM2cK5c+OJGE9mZmZ4efnR2hoaJby0NBQAgMDDRTVq+fp6Ymrq2uWfkhPT2fnzp26fvDz88PU1DRLnbi4OE6cOKGrExAQwJ07dzhw4ICuzr///sudO3fyfX8qisKAAQNYtWoV27Ztw9PTM8vn0kdZKYpCWlpake+XJk2aEBERQXh4uO7l7+9P165dCQ8Px8vLq0j3z+PS0tKIiorCzc2tcP7svNJhYIXEw0eU5s6dq0RGRipDhgxRrK2tlQsXLhg6tDyVlJSkHD16VDl69KgCKFOmTFGOHj2qexRr0qRJir29vbJq1SolIiJC6dKlS46PCpQsWVLZsmWLcuTIEaVx48Y5PipQtWpVZd++fcq+ffsUX1/ffP8YhaIoyocffqjY29srO3bsyPI4xb1793R1imofDR8+XNm1a5cSExOjHD9+XBkxYoRiZGSkbN68WVGUotsvT/Lf0dGKUrT7Z9iwYcqOHTuU8+fPK/v371fatGmj2Nra6n6/Fra+kST8nH766SfFw8NDMTMzU2rWrKl7LKUw2b59uwJke4WEhCiKon1cYMyYMYqrq6tibm6u1K9fX4mIiMjSxv3795UBAwYoxYsXVywtLZU2bdoosbGxWercuHFD6dq1q2Jra6vY2toqXbt2VW7duvWKvuXzy6lvAGX+/Pm6OkW1j3r16qX791GiRAmlSZMmugSsKEW3X57k8SRclPvn4XO/pqamiru7u/L2228rJ0+e1H1e2PpGVlESQgghDETuCQshhBAGIklYCCGEMBBJwkIIIYSBSBIWQgghDESSsBBCCGEgkoSFEEIIA5Ek/ALS0tIYO3YsaWlphg4lX5L+eTLpm9xJ/+RO+ufJClrfyHPCL+Du3bvY29tz584d7OzsDB1OviP982TSN7mT/smd9M+TFbS+kTNhIYQQwkAkCQshhBAGUuTWE87MzOTo0aO4uLhgZPRif4MkJSUBcOXKFe7evZsX4RUq0j9PJn2TO+mf3En/PFl+6BuNRsO1a9eoUaMGJia5p9kid0/44MGD1K5d29BhCCGEKOQOHDhArVq1cq1T5M6EHy7YfODAAdzc3AwcjRBCiMImLi6O2rVr6/JNbopcEn54CdrNzY2SJUsaOBohhBCF1bPc8pSBWUIIIYSBGDQJ79q1i7Zt2+Lu7o5KpWLNmjVP3Wfnzp34+flhYWGBl5cXP//888sPVAghhHgJDJqEU1JSqFatGjNmzHim+jExMbRq1Yp69epx9OhRRowYwaBBg1i5cuVLjlQIIYTIewa9J9yyZUtatmz5zPV//vlnSpcuzbRp0wCoVKkShw4d4vvvv6d9+/Z5GptarSYjIyNP2xQiPzAzM3vhx/OEEHmjQA3M2rdvH82bN89S1qJFC+bOnUtGRgampqYvfAxFUYiPj+f27dsv3JYQ+ZGRkRGenp6YmZkZOhTxBPfSMzl88RaZ6iL1BGm+UKq4JeWcbV/Z8QpUEo6Pj8825NvFxYXMzEwSExNzfOQoLS0ty0TeDx/kzu0Yt2/fxtnZGSsrK1QqVd4EL0Q+oNFouHr1KnFxcZQuXVp+vvMZRVHYdCKe8esiibuTauhwiqS+9b0Y0arSKztegUrCQLZfGg/nGnnSL5OJEycybty4Z2pbrVbrErCjo+OLBSpEPlWiRAmuXr1KZmZmnlw9EnkjJjGFMWtPsuv0dQCcbc1xtbcwcFRFj6vdq+3zApWEXV1diY+Pz1KWkJCAiYnJE5Pm8OHDGTp0qG77ypUrVK5cOce6D+8BW1lZ5VHEQuQ/Dy9Dq9VqScL5QGqGmpk7zvHzjnOkqzWYGRvRr2FZPmpYFgtTY0OHJ16yApWEAwIC+Pvvv7OUbd68GX9//yf+MjE3N8fc3Fy3/SxzicolOlGYyc93/rHt1DXGrD3JpZv3AahfoQTj3qyCp5O1gSMTr4pBk3BycjJnz57VbcfExBAeHk7x4sUpXbo0w4cP58qVK/z+++8A9OvXjxkzZjB06FDef/999u3bx9y5c1myZImhvoIQQujt8q17jPs7ktDIawC42Vswuk1lgnxc5Y+kIsagzykcOnSIGjVqUKNGDQCGDh1KjRo1GD16NKCdfzM2NlZX39PTkw0bNrBjxw6qV6/OV199xfTp0/P88SSh1bBhQ4YMGfLM9S9cuIBKpSI8PPylxSREQZaeqeGn7WdpOmUnoZHXMDFS8UF9L7YMbUBLXzdJwEWQQc+EGzZsSG6LOP3222/Zyho0aMCRI0deYlQFz9P+4YaEhOTYl0+zatUqve4ZlipViri4OJycnPQ+lhCF3d6ziYz66wTnr6cAUMezOF8F+1DB5dU9DiPynwJ1T1jkLC4uTvd+2bJljB49mujoaF2ZpaVllvrP+kx18eLF9YrD2NgYV1dXvfYpLNLT0+W5W5Gja3dTmbA+ir+PXQXAycacL1tXol11dznzFbKAQ2Hg6uqqe9nb26NSqXTbqampFCtWjOXLl9OwYUMsLCxYtGgRN27coEuXLpQsWRIrKyt8fX2z3Vt//HJ0mTJl+Oabb+jVqxe2traULl2a2bNn6z5//HL0jh07UKlUbN26FX9/f6ysrAgMDMzyBwLAhAkTcHZ2xtbWlj59+vDFF19QvXr1J35ftVpN79698fT0xNLSEm9vb3744Yds9ebNm0eVKlUwNzfHzc2NAQMG6D67ffs2ffv2xcXFBQsLC3x8fFi3bh0AY8eOzXb8adOmUaZMGd12jx49CA4OZuLEibi7u1OhQgUAFi1ahL+/P7a2tri6uvLuu++SkJCQpa2TJ0/SunVr7OzssLW1pV69epw7d45du3Zhamqa7QmAYcOGUb9+/Sf2h8ifMtUa5u6Jocnknfx97CpGKggJ8GDrsAYE13hNErAAJAk/laIo3EvPNMgrt0v1+vr8888ZNGgQUVFRtGjRgtTUVPz8/Fi3bh0nTpygb9++dOvWjX///TfXdiZPnoy/vz9Hjx7lo48+4sMPP+TUqVO57jNy5EgmT57MoUOHMDExoVevXrrPFi9ezNdff823337L4cOHKV26NLNmzcq1PY1GQ8mSJVm+fDmRkZGMHj2aESNGsHz5cl2dWbNm0b9/f/r27UtERARr166lXLlyuv1btmxJWFgYixYtIjIykkmTJmFsrN/jIFu3biUqKorQ0FBdAk9PT+err77i2LFjrFmzhpiYGHr06KHb58qVK9SvXx8LCwu2bdvG4cOH6dWrF5mZmdSvXx8vLy8WLlyoq5+ZmcmiRYvo2bOnXrEJwzp04SZtftzDV+siSU7LpHqpYqwdUJdx7Xywt5THwsQjcjn6Ke5nqKk8+h+DHDtyfAuszPLmf9GQIUN4++23s5R98sknuvcDBw5k06ZNrFixgjp16jyxnVatWvHRRx8B2sQ+depUduzYQcWKFZ+4z9dff02DBg0A+OKLL2jdujWpqalYWFjw448/0rt3b12SGT16NJs3byY5OfmJ7ZmammaZgMXT05OwsDCWL19Ox44dAe3Z9bBhwxg8eLCuXq1atQDYsmULBw4cICoqSncG6+Xl9cTjPYm1tTW//vprlsvQ//0Dw8vLi+nTp1O7dm2Sk5OxsbHhp59+wt7enqVLl+puCTyMAaB3797Mnz+fTz/9FID169dz79493fcS+duN5DQmbjzFn4cvA1DMypTPgyrSyb8URkZy5iuykzPhIsLf3z/Ltlqt5uuvv6Zq1ao4OjpiY2PD5s2bs4xGz0nVqlV17x9e9n78cmtu+zycWvThPtHR0dSuXTtL/ce3c/Lzzz/j7+9PiRIlsLGxYc6cObrYExISuHr1Kk2aNMlx3/DwcEqWLJkl+T0PX1/fbPeBjx49Srt27fDw8MDW1paGDRsC6GILDw+nXr16T7wn36NHD86ePcv+/fsB7SX1jh07Ym0tz43mZ2qNwqL9F2k8eacuAXeuVYptwxrSpXZpScDiieRM+CksTY2JHN/CYMfOK4//Ep88eTJTp05l2rRp+Pr6Ym1tzZAhQ0hPT8+1nceTh0qlQqPRPPM+D++D/XefJ01F+iTLly/n448/ZvLkyQQEBGBra8v//vc/3aX0xweiPe5pnxsZGWWLIacVtR7v05SUFJo3b07z5s1ZtGgRJUqUIDY2lhYtWuj69WnHdnZ2pm3btsyfPx8vLy/dI3ki/4q4fIcv10Rw7PIdACq72fFVsA9+Hg4GjkwUBJKEn0KlUuXZJeH8ZPfu3bRr14733nsP0CbFM2fOUKnSq5u4HMDb25sDBw7QrVs3XdmhQ4dy3Wf37t0EBgbqLosDnDt3Tvfe1taWMmXKsHXrVho1apRt/6pVq3L58mVOnz6d49lwiRIliI+PR1EU3R8Iz/Ls86lTp0hMTGTSpEmUKlUqx+9StWpVFixYkOsI9T59+tC5c2dKlixJ2bJleeONN556bPHq3bmXwfebo1n070UUBWzNTRjWvALvve6BifELXmTUqOFmDGgys39m6wKWDxJ8WjLcuQwmZlD8P7dUbpwDtZ5LsVo7aV8AGalw6wIYmYBTuUd1bl3QfqYPSwdtzKCN6caDf6vO/7mFdeey9rvow9wW7F/TvlcUuP5gwKdTeTB6cAJzNw5S7zx7m//tg1ek8GUX8UzKlSvHypUrCQsLw8HBgSlTphAfH//Kk/DAgQN5//338ff3JzAwkGXLlnH8+PFc79GWK1eO33//nX/++QdPT08WLlzIwYMH8fT01NUZO3Ys/fr1w9nZmZYtW5KUlMTevXsZOHAgDRo0oH79+rRv354pU6ZQrlw5Tp06hUqlIigoiIYNG3L9+nW+++47OnTowKZNm9i4cSN2dna5fpfSpUtjZmbGjz/+SL9+/Thx4gRfffVVljoDBgzgxx9/pHPnzgwfPhx7e3v2799P7dq18fb2BrTLc9rb2zNhwgTGjx//Ar0rXgZFUVh55AoTN0RxI0V7hSO4ujsjWlfC2fYFJ/9Pvwfhi2HfT3ArJuc6bX8Avx7a95cPwMK3wMUXPtzzqM7iDnDzvH7Hbvwl1NeORSDxNPxSD2zdYNh/Bl6u6guXch+8mU2dD6HlJO37lOsws442uY++8ajOhs8ger1+7fq+A+1/1b7XZGrbBfj8IlgW077f8Q0c+f3Z22zwBTQarl8cL0iScBE1atQoYmJiaNGiBVZWVvTt25fg4GDu3NHjr8Y80LVrV86fP88nn3xCamoqHTt2pEePHhw4cOCJ+/Tr14/w8HA6deqESqWiS5cufPTRR2zcuFFXJyQkhNTUVKZOnconn3yCk5MTHTp00H2+cuVKPvnkE7p06UJKSgrlypVj0iTtL4pKlSoxc+ZMvvnmG7766ivat2/PJ598kuVxrJyUKFGC3377jREjRjB9+nRq1qzJ999/z5tvvqmr4+joyLZt2/j0009p0KABxsbGVK9ePcvZrpGRET169OCbb76he/fuevepeHlOxd9l1JoTHLxwC4DyzjaMb+dDQNkXXHUt+TocnAMH5sD9m9oyE0swy2ExGZP/JHojU7ByfJR0HrIopi3Xh+l/jmVk/KDdxy6pW9jr3+5/v4PKSLu/0WOpx9z2Odq1ybr9cP//3t4ys9GvXdPcbxe9DColL5+DKQAuX75MqVKluHTpEiVLlszyWWpqKjExMXh6emJhIUuIGUqzZs1wdXXN8qhOUfP+++9z7do11q5dm+dty8+5/pLTMpkWepr5YRdQaxQsTY0Z3LQ8vd7wxMzkBS493zgHYT/CsSWQ+eAybzEPCBgANbqCmQzIK4hyyzOPkzNhYVD37t3j559/pkWLFhgbG7NkyRK2bNlCaGiooUMziDt37nDw4EEWL17MX3/9ZehwijxFUVgfEcdX6yK5djcNgJY+roxqUxn3Ynlw1hT5Fxyer33vXhPeGASV3nx0T1MUepKEhUGpVCo2bNjAhAkTSEtLw9vbm5UrV9K0aVNDh2YQ7dq148CBA3zwwQc0a9bM0OEUaeeuJzPmr5PsOZsIgIejFePerEJDb+fna1CjhlPrtZeOPR/MgObfC+LCofYH4BGY9VKqKBIkCQuDsrS0ZMuWLYYOI9+Qx5EM7366mp+2n+WXXefIUCuYmRjRv2E5PmjghcWLPDa47ycIHQWv+UOfLdqEa1kMOuoxcEgUOpKEhRDigdDIa4xde5Irt+8D0Mi7BGPfrIKH43Pcm01JhPu3tI/MAFTrrE3EXg20o3mNZfpKIUlYCCG4dPMeY9eeZOsp7UxurxWzZHTbyjSv7KL/Qgs3zsG+GRD+B5SqDSF/a8ttnOHjk2Asv3bFI/LTIIQostIy1czeeZ4Z28+SlqnB1FhFn3peDGxcTv9Jei4dgLDpELUOePDQSVqSdhIK8weP00gCFo+RnwghRJG06/R1xqw9SUxiCgABXo58FVyFcs62z96IRg3RG7XJ97+TWJRvoR3p7PGGDLYSuZIkLIQoUuLu3GfCuijWR8QBUMLWnC9bV+LNau7Pfuk547722d6wGXDzwTSMxmZQtSMEDMw6JaMQuZAkLIQoEjLUGubvjWHaljPcS1djpIKQwDJ83KwCdhbPOEgq5caDma1mw70H0y5a2IN/b6jzAdi6vrwvIAolWcpQ6DRs2JAhQ4botsuUKcO0adNy3UelUrFmzZoXPnZetSNETv49f4PW03fzzYZT3EtX4+fhwLqB9RjTtsqzJ2DQPmK0Y6I2AduXhqBJ8HEkNB0jCVg8FzkTLgTatm3L/fv3c3zedt++fQQGBnL48GFq1qypV7sHDx7M83Vsx44dy5o1a7KtShQXF4eDgyz9JvLW9aQ0Jm6IYtXRKwAUtzbji6CKdPAr+Wxr/F4+BFbFH61Q9PqHcO0kBA6EysEy0Eq8MPkJKgR69+7N22+/zcWLF/Hw8Mjy2bx586hevbreCRi0CxK8Kq6uRfMsIj09HTMzM0OHUeioNQqL/73I//6JJik1E5UKutQuzWctvClm9Yz9vfUr2P09VH8Pgn/Slrn6Qt8dMthK5Bm5HF0ItGnTBmdnZ3777bcs5ffu3WPZsmX07t2bGzdu0KVLF0qWLImVlRW+vr4sWbIk13Yfvxx95swZ6tevj4WFBZUrV85xfufPP/+cChUqYGVlhZeXF6NGjSIjQ7uu6W+//ca4ceM4duwYKpUKlUqli/nxy9ERERE0btwYS0tLHB0d6du3L8nJj9Yb7dGjB8HBwXz//fe4ubnh6OhI//79dcfKyblz52jXrh0uLi7Y2NhQq1atbFcP0tLS+OyzzyhVqhTm5uaUL1+euXPn6j4/efIkrVu3xs7ODltbW+rVq6dby/jxy/kAwcHB9OjRI0ufTpgwgR49emBvb8/777//1H57aO3atfj7+2NhYYGTkxNvv/02AOPHj8fX1zfb9/Xz82P06NFP7I/C6mjsLdr9tIfRf50kKTUTn9fsWP3RG3zzlm/uCTgjVTu5xkMVWmhXKTI21a5X+5AkYJGH5Ez4WaWn6L+Psfmjy1XqTFCnaZfy+u9yWU9qV4/VU0xMTOjevTu//fYbo0eP1o3wXLFiBenp6XTt2pV79+7h5+fH559/jp2dHevXr6dbt254eXlRp06dpx5Do9Hw9ttv4+TkxP79+7l79262hANga2vLb7/9hru7OxEREbz//vvY2try2Wef0alTJ06cOMGmTZt0yc/e3j5bG/fu3SMoKIjXX3+dgwcPkpCQQJ8+fRgwYECWPzS2b9+Om5sb27dv5+zZs3Tq1Inq1avrEtvjkpOTadWqFRMmTMDCwoIFCxbQtm1boqOjKV26NADdu3dn3759TJ8+nWrVqhETE0Nionbu4CtXrlC/fn0aNmzItm3bsLOzY+/evWRm5rDwei7+97//MWrUKL788stn6jeA9evX8/bbbzNy5EgWLlxIeno669dr11/t1asX48aN4+DBg9SqVQuA48ePc/ToUVasWKFXbAXZ7XvpfLspmqUHY1EUsLUw4bMW3rxbxwPj3C4937sJB3/VDraq8ha0+p+2vFRt7Vq6r3iRd1HEKEXMpUuXFEC5dOlSts/u37+vREZGKvfv38++4xg7/V8nVj3a/8Qqbdm8Vlnb/dYz5331FBUVpQDKtm3bdGX169dXunTp8sR9WrVqpQwbNky33aBBA2Xw4MG6bQ8PD2Xq1KmKoijKP//8oxgbG2fpt40bNyqAsnr16ice47vvvlP8/Px022PGjFGqVauWrd5/25k9e7bi4OCgJCcn6z5fv369YmRkpMTHxyuKoighISGKh4eHkpmZqavzzjvvKJ06dXpiLDmpXLmy8uOPPyqKoijR0dEKoISGhuZYd/jw4Yqnp6eSnp6e4+eP95+iKEq7du2UkJAQ3baHh4cSHBz81Lge77eAgACla9euT6zfsmVL5cMPP9RtDxkyRGnYsGGOdXP9OS+A1GqNsuxArFJj/GbF4/N1isfn65SPlx1VEu6m5r7jjfOKsm6Yonzl8ujf3Y+1FEWdmft+QjxFbnnmcXImXEhUrFiRwMBA5s2bR6NGjTh37hy7d+9m8+bNAKjVaiZNmsSyZcu4cuUKaWlppKWlPfPAq6ioKEqXLp1lbcyAgIBs9f7880+mTZvG2bNnSU5OJjMzEzs7O72+S1RUFNWqVcsS2xtvvIFGoyE6OhoXFxcAqlSpgrHxown13dzciIiIeGK7KSkpjBs3jnXr1nH16lUyMzO5f/8+sbGxAISHh2NsbEyDBg1y3D88PJx69ephavpic/76+/tnK3tav4WHhz/xDB+06w/36tWLKVOmYGxszOLFi5k8efILxVkQRF69y6i/TnD4ovYysreLLV8F+1Dbs/iTd7p8GMJ+gKi/QdFoy1yrwhuDoXI7WUZQvFKShJ/ViKv672Ns/uh9xbbaNlSP3YYf8uSkoa/evXszYMAAfvrpJ+bPn4+HhwdNmjQBYPLkyUydOpVp06bh6+uLtbU1Q4YMIT09/ZnaVv57T+yBxyc22L9/P507d2bcuHG0aNECe3t7li5dqncyUBTliZMm/Lf88WSoUqnQaDRPbPfTTz/ln3/+4fvvv6dcuXJYWlrSoUMHXR9YWua+PuzTPjcyMsrWTzndo378D59n6benHbtt27aYm5uzevVqzM3NSUtLo3379rnuU5AlpWYwJfQ0C8IuoFHA2syYIU0r0OONMpga5zDURaOBM//A3ukQG/aovFwz7Uhnz/pyr1cYhCThZ6XHPdocGZvk/DjDi7b7Hx07dmTw4MH88ccfLFiwgPfff1+XtHbv3k27du147733AO093jNnzlCpUqVnarty5crExsZy9epV3N3dAe3jT/+1d+9ePDw8GDlypK7s4sWLWeqYmZmhVqufeqwFCxaQkpKiS1h79+7FyMiIChUqPFO8Odm9ezc9evTgrbfeArT3iC9cuKD73NfXF41Gw86dO3Ncz7hq1aosWLCAjIyMHM+GS5QoQVxcnG5brVZz4sQJGjVqlGtcz9JvVatWZevWrfTs2TPHNkxMTAgJCWH+/PmYm5vTuXNnrKyscj1uQaQoCmuPXWXC+iiuJ6UB0LqqG6NaV8bV3iL7DhmpcHyZdkGFxNPaMiPTBzNbDQCXyq8weiGyk9HRhYiNjQ2dOnVixIgRXL16Ncuo3HLlyhEaGkpYWBhRUVF88MEHxMfHP3PbTZs2xdvbm+7du3Ps2DF2796dJWk8PEZsbCxLly7l3LlzTJ8+ndWrV2epU6ZMGWJiYggPDycxMZG0tLRsx+ratSsWFhaEhIRw4sQJtm/fzsCBA+nWrZvuUvTzKFeuHKtWrSI8PJxjx47x7rvvZjlzLlOmDCEhIfTq1Ys1a9YQExPDjh07WL58OQADBgzg7t27dO7cmUOHDnHmzBkWLlxIdHQ0AI0bN2b9+vWsX7+eU6dO8dFHH3H79u1niutp/TZmzBiWLFnCmDFjiIqKIiIigu+++y5LnT59+rBt2zY2btxIr169nruf8quzCUm8O+dfBi8N53pSGp5O1izsXZuf3q2ZcwIGWNYV/h6kTcDm9vDGEBhyHIJnSgIW+YIk4UKmd+/e3Lp1i6ZNm+pG/AKMGjWKmjVr0qJFCxo2bIirqyvBwcHP3K6RkRGrV68mLS2N2rVr06dPH77++ussddq1a8fHH3/MgAEDqF69OmFhYYwaNSpLnfbt2xMUFESjRo0oUaJEjo9JWVlZ8c8//3Dz5k1q1apFhw4daNKkCTNmzNCvMx4zdepUHBwcCAwMpG3btrRo0SLb89OzZs2iQ4cOfPTRR1SsWJH333+flBTtCHZHR0e2bdtGcnIyDRo0wM/Pjzlz5ujOinv16kVISAjdu3enQYMGeHp6PvUsGJ6t3xo2bMiKFStYu3Yt1atXp3Hjxvz7779Z6pQvX57AwEC8vb2facR7QXEvPZNJG0/R8ofd7Dt/A3MTIz5pXoFNQ+pRr/xjz7LfjNGuXPRQtS5gVxJafAMfn4Bm48DO/dV+ASFyoVJyutlXiF2+fJlSpUpx6dKlLIOMAFJTU4mJicHT0xMLiyf8ZS1EPqUoChUrVuSDDz5g6NChT6xXUH7OFUXhn5PX+GpdJFdu3wegaSVnxrStQqniOVxqDx2jXc2o2XjtfV7QrnKkaLTP+grxiuSWZx4n94SFKAQSEhJYuHAhV65ceeJ944Lk4o0Uxqw9yY7o6wC8VsySsW9WoVnl/9yO0GgeJNgHv8Ycy2q3E049qmNkDMhoZ5F/SRIWohBwcXHBycmJ2bNnF+g5uFMz1Py88xwzd5wjPVODqbGKD+qXpX+jcliaPUimGakQsVy7jGCdD6BWb225b0dwrwmuPob7AkLoSZKwEIVAYbirtD06gbFrT3Lxxj0A6pZzYly7KpQtYaOtcP8WHJwL//4CKQnasiO/P0rCphaSgEWBI0lYCGFQV2/fZ/zfkWw6qR2t72Jnzqg2lWnt66Z9xO7WRdg/E44shIwH07zavaZd0ahmiAEjF+LFSRIWQhhEeqaGuXtimL71DPcz1BgbqegZWIYhzSpgY24CV45A2I8QuebRzFYuvtpBVz5vy2ArUShIEs5BbrMuCVHQ5YdL1/vO3WDUXyc4m6BdGatWGQe+CvahorMNnA3VJt8Lux/t4NUI3hik/a/MbCUKEUnC/2FmZoaRkRFXr16lRIkSmJmZPXH6RCEKIkVRuH79OiqV6oXnwH4eCXdT+XpDFH+Fa6eBdbQ2Y0SrSrxd8zVUAPNbPZpW0sgEfDpA4ADtOr5CFEKShP/DyMgIT09P4uLiuHr1OeaKFqIAUKlUlCxZMsviFy9bplrDwv0XmbL5NElpmahU8F4dDz6p74q9g+Ojs9syb0B8BPj3gDr9wD73ZyyFKOgkCT/GzMyM0qVLk5mZ+dQ5joUoiExNTV9pAj588Raj1pwgMu4uANVK2vNVsA9VT8+AWTOh4+9Q/sFc3QEDtPd8LbKvMy1EYSRJOAcPL9UZ4nKdEIXFzZR0vt14imWHLgFgb2nKZ0HedK5VGmMjFZy4px3tfOrvR0nYspjhAhbCACQJCyHylEajsOzQJb7ddIrb9zIAhS8rXCFEWYupywgw8tBWDOgP5ZpA2cYGjVcIQ5IkLITIMyeu3OHLNScIv3QbMzIY6HCEj8w3Yhn7YBnBfT9p7/sC2L+mfQlRhEkSFkK8sDv3M5iyOZqF+y9io6QwyHw7/cxDsbp/He4DZjbg10M72EoIoSNJWAjx3BRFYU34Fb5efwrz5MuMMNnEe6Y7sFDuQzpg66ZNvH495H6vEDmQJCyEeC6nryUxas0Jki8c4UuTdbS12I8xGlAA58oPZrbqACZmhg5ViHzLyNABzJw5U7euqZ+fH7t37861/k8//USlSpWwtLTE29ub33///RVFKoQASEnL5JsNUbz5w3b6X/6U9eYjCDYO0yZgzwbQdSV8GAbV35UELMRTGPRMeNmyZQwZMoSZM2fyxhtv8Msvv9CyZUsiIyMpXbp0tvqzZs1i+PDhzJkzh1q1anHgwAHef/99HBwcaNu2rQG+gRBFh6IobIy4ylfrTxF3JxUwxraYHcp9Y1Q+b2vPfN2qGTpMIQoUlWLAiWTr1KlDzZo1mTVrlq6sUqVKBAcHM3HixGz1AwMDeeONN/jf//6nKxsyZAiHDh1iz549z3TMy5cvU6pUKS5dukTJkjIbjxDPIuZ6Mv8uGkPd22vokj4SHMow7s0qNC6RDMZmUKyUoUMUIt/QJ8/ofTm6TJkyjB8/ntjY2OcOECA9PZ3Dhw/TvHnzLOXNmzcnLCwsx33S0tKwsLDIUmZpacmBAwfIyMh44j53797VvZKSkl4obiGKjIz7XL19nwnrImkxbTfuN/+lpCqRyV5HCf24AY0ruoBjWUnAQrwAvZPwsGHD+Ouvv/Dy8qJZs2YsXbqUtLQ0vQ+cmJiIWq3GxcUlS7mLiwvx8fE57tOiRQt+/fVXDh8+jKIoHDp0iHnz5pGRkUFiYmKO+0ycOBF7e3vdq3LlynrHKkSRkRQPh38jad7bpH9Tmu7f/cGve2JIV2vY4d6b642nULvn91iYvrppL4UozPROwgMHDuTw4cMcPnyYypUrM2jQINzc3BgwYABHjhzRO4DHVylSFOWJKxeNGjWKli1b8vrrr2Nqakq7du3o0aMHwBPnwh0+fDh37tzRvSIjI/WOUYhCS1Eg/gTs/B/K7EYw2Rv+Hoxt7FbMlHReV0UQ4OXI/J61GNWvByXq9wYTc0NHLUSh8dwDs6pVq8YPP/zA999/z8yZM/n888+ZNWsWPj4+DB48mJ49e+a6DKCTkxPGxsbZznoTEhKynR0/ZGlpybx58/jll1+4du0abm5uzJ49G1tbW5ycnHLcx9zcHHPzR7807t69+xzfVohCJDNdu1bv6U0QvRHuaOd2fviv9aimHNs0NUkrF0SnJk3wLVXMYKEKUdg9dxLOyMhg9erVzJ8/n9DQUF5//XV69+7N1atXGTlyJFu2bOGPP/544v5mZmb4+fkRGhrKW2+9pSsPDQ2lXbt2uR7b1NRUd7N76dKltGnTBiMjgz9tJUT+dmoDHF8GZ7dC+qOxEamYsVvtS6imJvuN/WlSy5deb3hSqriVAYMVomjQOwkfOXKE+fPns2TJEoyNjenWrRtTp06lYsWKujrNmzenfv36T21r6NChdOvWDX9/fwICApg9ezaxsbH066ed2m748OFcuXJF9yzw6dOnOXDgAHXq1OHWrVtMmTKFEydOsGDBAn2/hhCFX+JZcPAA4wergZ3fDpFrAEg2dWRjenU2ZtQgTFMFW1s7egSWYWQdD+ytZPUwIV4VvZNwrVq1aNasGbNmzSI4ODjH5f4qV65M586dn9pWp06duHHjBuPHjycuLg4fHx82bNiAh4d2lZW4uLgso7DVajWTJ08mOjoaU1NTGjVqRFhYGGXKlNH3awhRuM1tAZf2Q8g68KwHQIxbK844pjIrvgLhqWVQMKKcsw3j63nRroY75iYy2EqIV03v54QvXryoS5IFkTwnLAqVtCTt5eWLe6Hld/BwHMbqfhDxJ0rQJPY4tGP2rvPsPvPoCYLXvYrTt74XDSs4Y2T05LEbQgj96ZNn9D4TTkhIID4+njp16mQp//fffzE2Nsbf31/fJoUQ+rh96cGgqg1wYQ+o07Xl1buCe3UAMhqOZNNrg5m5L5GouAMAGKmgla8bfet7UbVkMcPELoTIQu8k3L9/fz777LNsSfjKlSt8++23/Pvvv3kWnBAC0Ggg7ihEPxjNfC0i6+fFy4J3S7CwJyk1g6UHLjFvb8yDqSXB0tSYTrVK0buuDLYSIr/ROwlHRkZSs2bNbOU1atSQZ3CFyCsZ9+H8Tji9UZt8k//zKJ/KCEq9Dt5B4N0KnMoTfyeV+Xtj+OPfbSSlZQLgZGNOzzfK0LVOaYpZyUIKQuRHeidhc3Nzrl27hpeXV5byuLg4TExkZUQh8sS8IIgLf7RtZgPlmkCFllC+OVg7AnAq/i6zl4ezNvwqmRrt8I6yJazpW9+LdtVfk5mthMjn9M6azZo1Y/jw4fz111/Y29sDcPv2bUaMGEGzZs3yPEAhCrXMNAj7Ec5th/f+BFNLbXnZRpCSqL3M7B0EZerpZqpSFIWws4n8sus8u05f1zVVx1M72KqRtwy2EqKg0DsJT548mfr16+Ph4UGNGjUACA8Px8XFhYULF+Z5gEIUKuoMuHEOnB88V29sBofmw93LELMLKrTQljf4HJqMeTTaGchQa9gQEcfsXec5eVU785uRClr6uPF+fS+qy8xWQhQ4eifh1157jePHj7N48WKOHTuGpaUlPXv2pEuXLjk+MyxEkXf/FpzZor2/e2YLGBnBJ2fB2ESbZOsN1f7X/T9jLR6eEQPJaZksPRDL/L0XuHL7PqAdbNXRvyS963pR2lEGWwlRUD3XTVxra2v69u2b17EIUXjcPK8dyRy9ES6GgaJ+9JmVE9y+qF0GEKBW7xybuHY3lXl7Y/jj31iSUh8OtjKjR2AZutbxwMFaBlsJUdA990iqyMhIYmNjSU9Pz1L+5ptvvnBQQhQ4GjVcPqR9djd6IyRGZ/28RKVHo5lf8wOjJw+Yio5PYs7u8/wVfoUMtXawlVcJa/rW8yK4hgy2EqIw0TsJnz9/nrfeeouIiAhUKhUPJ9x6uGKSWq3ObXchCheNGtYO0l5qvnfjUbmRCXgEapNuhSAo7plrM4qisO/cDX7ZdZ6d/xlsVbuMdrBV44oy2EqIwkjvJDx48GA8PT3ZsmULXl5eHDhwgBs3bjBs2DC+//77lxGjEPnH3atw9ShUbK3dNjKG61HaBGxhD+WaaUc0l2sKlsWe2lymWsP6iDjm7D7PiSuPBlsF+bjyfj0vapR2eIlfRghhaHon4X379rFt2zZKlCiBkZERRkZG1K1bl4kTJzJo0CCOHj36MuIUwvBuX4JpPtqz3M/Oa5MuQOMvtWWlAx6tWPQUyWmZLDt4iXl7YnSDrSxMjejor53ZysPR+mV9CyFEPqJ3Elar1djY2ADg5OTE1atX8fb2xsPDg+jo6KfsLUQBkJGqXfQ+eqN2u80U7X+LldLe27Wwg6Rrj5Jw2cbP3PS1u6n8FnaBxfsvcvfBYCtHazNCAsvQ7XUZbCVEUaN3Evbx8eH48eN4eXlRp04dvvvuO8zMzJg9e3a2WbSEKDBSEuH0P9qBVee2Q0aKttzUClp8A6YW2u0PduomzdDH6WtJzNl1njX/HWzlZE2fel68XVMGWwlRVOmdhL/88ktSUrS/oCZMmECbNm2oV68ejo6OLFu2LM8DFOKlUBRIPP1oNPOlA8B/VvW0ddMOqPJulXUksx4JWFEU9p2/wZxd59ke/WiwVa0yDrxfz4umlVxksJUQRZzeSbhFixa6915eXkRGRnLz5k0cHBx0I6SFyJfUmRC7T5t0T2/UPsv7X65VH0wT2RLcqmeZrUofmWoNG07EM2fXeSKu3AG0TQVVceX9+l7UlMFWQogH9ErCmZmZWFhYEB4ejo+Pj668ePHieR6YEHlCo350JpueDAuDQaO9F4uxGXjWf3DG2xLsc198+2lSHgy2mvvYYKt3/LSDrco4yWArIURWeiVhExMTPDw85Flgkf8lRMGmLyAzHXo9GGBlWQwqttHe5/UO0g6oMrd98UPdTWXBvgss2h/LnfsZABS3NiMkoAzdAjwoLoOthBBP8Fz3hIcPH86iRYvkDFjkDxoNXD2ivc9bqpa2zKIYnN8BqLSDrqydtOUdF+TZYc9c085steboVdLVGgA8nazpU8+T9jVLymArIcRT6Z2Ep0+fztmzZ3F3d8fDwwNr66yX2I4cOZJnwQnxROn3tEk2eoN2VHNKAng1gu5rtJ/buUHwz1Cq9qMEnAcUReHfmJvM3nWebacSdOV+Hg70ra8dbGUsg62EEM9I7yQcHBz8EsIQ4hmd3gyH5moTcGbqo3JzO7Bx1p4NPxxQVb1Lnh02U61h00ntYKtjlx8Ntmpe2YW+9b3w85CrQkII/emdhMeMGfMy4hAid5npEDoa/p31qKxY6UdzM3u8ASZ5f+/1Xnomyw9eYu7eGC7d1A62MjcxooNfSfrU88JTBlsJIV7Ac6+iJMQrc/sSrOgBVw5pt2t/AH4h4Fz5uR8jepqEpFR+D7vIwv0XdYOtHKxM6R5Qhu4BHjja6D9hhxBCPE7vJGxkZJTr88AyclrkqdP/wOoP4P4t7WCrt37WPk70kpxNSOLX3TGsOnJFN9iqjKMVvet50aFmSSzNZLCVECLv6J2EV69enWU7IyODo0ePsmDBAsaNG5dngQnB8RWwqo/2vXtNeOc3cPDI88MoisKBmJvM2X2eLVGPBlvVKF2MD+p70ayyqwy2EkK8FHon4Xbt2mUr69ChA1WqVGHZsmX07t07TwITgvLNwKEMlG8Bzb96rjmbc6PWKGw6Ec/s3ec5duk2oL263aySdrCVfxkZbCWEeLny7J5wnTp1eP/99/OqOVFUxZ8AlyrabGhZDD7Y9Wi1ojxyLz2TFYcu8+ue87rBVmYPBlv1rutJ2RI2eXo8IYR4kjxJwvfv3+fHH3+kZMkXm/ZPFHG7vodtE6D191DrwWXoPEzA15PS+H3fBRbuv8jte48GW3V7MNjKSQZbCSFeMb2T8OMLNSiKQlJSElZWVixatChPgxNFjIkFoEDCqTxt9tz1ZH7dfZ6VR66QnqkdbOXhaEWfup508Cslg62EEAajdxKeOnVqliRsZGREiRIlqFOnDg4OsjqM0FNm+qPnewP6g6sPeDV84WYVReHQxVv8svM8W6Ku6cqrl9IOtmpeRQZbCSEMT+8k3KNHj5cQhihyNBoI+wGOLYM+odqFFFSqF07Aao3C5pPx/LLrPOEPBlsBNK3kwgcNvPD3kCU3hRD5h95JeP78+djY2PDOO+9kKV+xYgX37t0jJCQkz4IThdS9m7DmQzi9Sbt9fDnUerFR9ffT1fx5+BK/7onh4o17gHawVfuaJelTTwZbCSHyJ72T8KRJk/j555+zlTs7O9O3b19JwiJ3lw9pZ7+6cwmMzaHVd1Dz+X9mEpPT+H3fRRbuu8CtB4OtilmZ0u11D7oHlKGErQy2EkLkX3on4YsXL+Lp6Zmt3MPDg9jY2DwJShRCigL//gKbvwRNBhT3gncWgFvV52ru/PVkft0Tw8rDl0l7MNiqdHEr+tTzpINfSazMZEZWIUT+p/dvKmdnZ44fP06ZMmWylB87dgxHR8e8iksUJql34K8BELVWu13pTWg347kePzpx5Q7Tt54hNOoaiqItq1bSnr71yxLkI4OthBAFi95JuHPnzgwaNAhbW1vq168PwM6dOxk8eDCdO3fO8wBFARd3HFaEwM3zYGQKLb6G2n31XnhBURTm7olh0sZTZGq02bdpJWfer+dFbc/iMthKCFEg6Z2EJ0yYwMWLF2nSpAkmJtrdNRoN3bt355tvvsnzAEUBpShwZAFs+AzUaWBfSjv3c0l/vZu6cz+Dz/48xj8ntY8atajiwqctvCnnbJvHQQshxKuldxI2MzNj2bJlTJgwgfDwcCwtLfH19cXDI+8n1hcFVPo9WDcEji/TbpdvoV39yEr/uZhPXLnDR4uPEHvzHqbGKka1qUy31z3kzFcIUSg89+iV8uXLU758+byMRRQWxqZwOxZUxtBkNAQOAiMjvZpQFIXF/8Yy/u9I0tUaSjpY8tO7NalWqtjLiVkIIQxA7yTcoUMH/P39+eKLL7KU/+9//+PAgQOsWLEiz4ITBYxGo022xqbQYR7cugAegXo3k5yWyYhVEaw9dhXQ3vud/E517K1M8zhgIYQwLP1OT9AOwmrdunW28qCgIHbt2pUnQYkCJuM+rB2kffzoITv350rAp+Lv8uaMPaw9dhVjIxUjW1ViTnd/ScBCiEJJ7zPh5ORkzMzMspWbmppy9+7dPAlKFDCx+7SDsFRG4N8TnJ7vNsWKQ5cY9dcJUjM0uNpZMOPdGrKmrxCiUNP7TNjHx4dly5ZlK1+6dCmVK1fOk6BEAVO2MTT+Et5b+VwJ+H66ms/+PManfx4nNUNDvfJOrB9UVxKwEKLQ0/tMeNSoUbRv355z587RuHFjALZu3coff/zBn3/+mecBinwoMx12fKNd89f+wRrS9T99rqbOXU+m/+IjnIpPwkgFHzetQP9G5TCSSTeEEEWA3kn4zTffZM2aNXzzzTf8+eefWFpaUq1aNbZt24adnd3LiFHkJ7cuwp894cphuBgGPTfpPfL5ob+PXeWLlcdJSVfjZGPO9M7VCSznlMcBCyFE/vVcvz1bt27N3r17SUlJ4ezZs7z99tsMGTIEPz8/vduaOXMmnp6eWFhY4Ofnx+7du3Otv3jxYqpVq4aVlRVubm707NmTGzduPM/XEPqK3gi/1NcmYItiUHfocyXgtEw1o9acYOCSo6Skq6njWZwNg+pKAhZCFDnPdwoDbNu2jffeew93d3dmzJhBq1atOHTokF5tLFu2jCFDhjBy5EiOHj1KvXr1aNmy5RMXgtizZw/du3end+/enDx5khUrVnDw4EH69OnzvF9DPAt1BoSOhiWdIfU2vOYH/XaDd5DeTV26eY8Os/axcP9FAPo3KsviPnVwtrPI46CFECL/0+ty9OXLl/ntt9+YN28eKSkpdOzYkYyMDFauXPlcg7KmTJlC7969dUl02rRp/PPPP8yaNYuJEydmq79//37KlCnDoEGDAPD09OSDDz7gu+++0/vY4hndvQp/9tKOgAao8yE0Gw8m2UfIP83mk/EMW3GMpNRMilmZMrVTdRp5O+dxwEIIUXA885lwq1atqFy5MpGRkfz4449cvXqVH3/88bkPnJ6ezuHDh2nevHmW8ubNmxMWFpbjPoGBgVy+fJkNGzagKArXrl3jzz//zPG5ZZEHzm2Dn+tqE7CZrXbpwZaT9E7AGWoNX6+PpO/CwySlZlKjdDHWD6onCVgIUeQ985nw5s2bGTRoEB9++GGeTFeZmJiIWq3GxcUlS7mLiwvx8fE57hMYGMjixYvp1KkTqampZGZm8uabb+b6x0BaWhppaWm67aSkpBeOvdDTqGHnt7DzO0ABV19tAnYsq3dTV2/fZ8AfRzgSexuAPnU9+SyoImYmz30nRAghCo1n/k24e/dukpKS8Pf3p06dOsyYMYPr16+/cACPT8SvKMoTJ+ePjIxk0KBBjB49msOHD7Np0yZiYmLo16/fE9ufOHEi9vb2upc8y/wUyQmw8C1tEkYBvx7QO/S5EvCO6ARaT9/Nkdjb2FqY8PN7fnzZprIkYCGEeOCZfxsGBAQwZ84c4uLi+OCDD1i6dCmvvfYaGo2G0NBQvc8wnZycMDY2znbWm5CQkO3s+KGJEyfyxhtv8Omnn1K1alVatGjBzJkzmTdvHnFxcTnuM3z4cO7cuaN7RUZG6hVnkbN7MsTsBFNreHsOtP0BTC31aiJTreH7f6Lp+dtBbt3LwOc1O9YNrEuQj+tLCloIIQomvU9JrKys6NWrF3v27CEiIoJhw4YxadIknJ2defPNN5+5HTMzM/z8/AgNDc1SHhoaSmBgznMO37t3D6PHHokxNjYGtGfQOTE3N8fOzk73srWVNWhz1XgUVHoT+m6Hqh313j0hKZX35v7LjO1nURR47/XS/NkvEA9H65cQrBBCFGwvdF3Q29ub7777jsuXL7NkyRK99x86dCi//vor8+bNIyoqio8//pjY2Fjd5eXhw4fTvXt3Xf22bduyatUqZs2axfnz59m7dy+DBg2idu3auLu7v8hXKbru3YRd38PDP2LMbaDTQijhrXdTYecSafXDHvafv4mVmTE/dK7OhGBfLEyN8zhoIYQoHJ57PeH/MjY2Jjg4mODgYL3269SpEzdu3GD8+PHExcXh4+PDhg0b8PDwACAuLi7LM8M9evQgKSmJGTNmMGzYMIoVK0bjxo359ttv8+JrFD3qDJjbDG6cBWMzeGPQczWj0SjM3HGWKaGn0Sjg7WLLT11rUs7ZJo8DFkKIwkWlPOk6biF1+fJlSpUqxaVLlyhZsqShwzG8Q/MgbAZ0XKAdBa2nmynpfLwsnJ2ntYP0OviV5Kt2PliaydmvEKJo0ifP5MmZsChAUu9A0jUoUUG77dcTqnYGMyu9mzp88SYD/jhK3J1UzE2M+CrYh47+pfI4YCGEKLwkCRclccdgeQgoavhgF1g6gEqldwJWFIW5e2KYtPEUmRoFLydrfupak0pusoCHEELoQ5JwUaAocHg+bPwC1GlgX1p7NmzpoHdTd+5n8MmKY4RGXgOgTVU3JrWvio25/CgJIYS+5DdnYZeWDOs+hojl2u0KLSF4JlgV17upiMt3+OiPw1y6eR8zYyNGtanEe697PHFyFSGEELmTJFyYJUTB8u6QeBpUxtB0DAQO0l6C1oOiKCzaf5Gv1kWRrtZQqrglM9/1w7ek/UsKXAghigZJwoVV+BLtGXDmfbB1gw7zwSNA72aS0zIZviqCv49dBaBZZRe+71ANeyvTvI5YCCGKHEnChU3GfdjwKRxdqN32agTtfwVrJ72bOhV/l48WHeF8YgomRiq+aFmR3nU95fKzEELkEUnChUniWVgRAtdOACpoNALqDQMj/Z/ZXX7oEqP/OkFqhgY3ewtmvFsDPw/97yMLIYR4MknChcW1SJjbHNKTwLqE9uzXq6HezdxPVzPqrxP8efgyAA0qlGBqp+oUt9ZvDWEhhBBPJ0m4sCjhDSX9tFNRdpgHtvqvWHQ2IZn+i48QfS0JIxUMbVaBjxqWw8hILj8LIcTLIEm4ILsdqz3rNbXUXnLu+Lt2CUJj/f+3/hV+hRGrIkhJV+NkY870LtUJLKv/fWQhhBDPTpJwQXV6M6zqA5WD4c3p2jIL/R8ZSs1QM2F9JIv2axfKeN2rONO71MDZ1iIPgxVCCJETScIFlbEppN6Faych/d5zzf0ce+MeH/1xmBNX7gIwsHE5Bjcpj4nxC61wKYQQ4hlJEi5I1JmPLjWXbQTv/Qll6oOJ/oOmNp2I59M/j5GUmomDlSlTO1WnobdzHgcshBAiN3LKU1Cc3Qoz/OHGuUdl5ZrqnYAz1BomrIuk36LDJKVm4ufhwPpB9SQBCyGEAciZcH6nUcOOSbDrf4Ci/e9bPz9XU1dv32fAH0c4EnsbgPfrefJZUEVM5fKzEEIYhCTh/Cw5AVb2hphd2m3/XtBi4nM1tT06gaHLwrl1LwNbCxMmv1ON5lX0f4xJCCFE3pEknF/F7NYm4ORr2seO2v4AVd/Ru5lMtYapW07z03btZWzf1+z56d2alHbUfyCXEEKIvCVJOL/RaGDPFNj+NSgaKFFJ+/xviQp6N5VwN5VBS4+y//xNALq97sGXbSphbqL/NJZCCCHyniTh/OTeTVjVF86GarerdYHWk8HMWu+mws4lMmhJOInJaVibGTOxfVXerOaexwELIYR4EZKE84tLB2BFT7h7GUwsoNX3UOM9vdf+1WgUftp+lqlbTqNRoKKrLT91rUnZEjYvKXAhhBDPS5KwoSkK7J8FoaNAkwnFy2ovP7v66N3UjeQ0Pl5+jF2nrwPQ0b8k4970wdJMLj8LIUR+JEnY0FQqSDytTcBV3oK208HCTu9mDl24yYA/jhJ/NxULUyO+aufDO/6lXkLAQggh8ookYUNRlEeXmoMmgUcg+L6j9+VnRVGYs/s8326KRq1R8CphzcyuNanoqn8iF0II8WpJEn7VFAUOzdUuwNBliXb1I1MLqNpR76bu3Mtg2IpjbIm6BsCb1dz55m1fbMzlf6sQQhQE8tv6Vbt7FTaPgox7cGLlcyVfgOOXb/PR4iNcvnUfM2MjRretTNc6pVHpeSYthBDCcCQJv2r2r2kn3kiK115+1pOiKCzcf5EJ66JIV2soXdyKmV1r4vOa/ssYCiGEMCxJwq/C0cVQ3FN73xee++w3KTWDL1ZFsP54HAAtqrjwXYdq2Fua5lWkQgghXiFJwi9T+j3Y8CmELwIbV/gwDKwdn6upqLi7fLT4CDGJKZgYqRjeqhK93igjl5+FEKIAkyT8siSegeUhkHASVEZQqw9YOujdjKIorDh0mVF/nSAtU4ObvQUz3q2Jn4f+bQkhhMhfJAm/DCdWwtpBkJ4M1s7Q/lfwaqB3M/fSMxm15iQrj1wGoKF3CaZ0rE5xa/3WEBZCCJE/SRLOS5lp8M8IOPirdtujLnSYC7b6Lxl4NiGJjxYf4fS1ZIxUMKy5Nx82KIuRkVx+FkKIwkKScF65dUF7+TkuXLtdbxg0HAHG+nfxX+FXGL4qgnvpakrYmjO9cw0Cyj7fvWQhhBD5lyThvHBqPaz+ENLuaO/7vj0HyjfTu5nUDDXj10Xyx7+xAASWdeSHzjUoYWue1xELIYTIByQJvwh1BmwZC/tmaLdL1oJ3fgP7kno3dfFGCh8tPsLJq3dRqWBgo3IMbloBY7n8LIQQhZYk4RdxYtWjBBwwAJqMARP9B01tOhHHpyuOk5SWSXFrM6Z2qk6DCiXyOFghhBD5jSThF1G1I5zfARVbQaW2eu+enqlh0sZTzNsbA4C/hwM/vlsDN3vLPA5UCCFEfiRJ+EWoVPDWrOfa9crt+/RffITwS7cB+KC+F5+08MbU2CgPAxRCCJGfSRI2gO2nEvh4eTi372VgZ2HC5I7VaVbZxdBhCSGEeMUkCb9CmWoNU0JPM3PHOQCqlrTnp3drUqq4lYEjE0IIYQiShF+Ra3dTGbjkKAdibgIQEuDBiNaVMDcxNnBkQgghDEWS8Cuw92wig5ceJTE5HRtzEya196VNVXdDhyWEEMLAJAm/RGqNwoxtZ5m29TSKAhVdbZnZtSZeJWwMHZoQQoh8QJLwS3IjOY0hy8LZfSYRgE7+pRjXrgoWpnL5WQghhJYk4Zfg4IWbDPzjKPF3U7E0NWZCsA/t/fSfRUsIIUThJkk4D2k0CnN2n+e7f6JRaxTKlrBm1nt+VHCxNXRoQggh8iGDzwwxc+ZMPD09sbCwwM/Pj927dz+xbo8ePVCpVNleVapUeYUR5+z2vXT6LjzExI2nUGsU2lV3Z+2AupKAhRBCPJFBk/CyZcsYMmQII0eO5OjRo9SrV4+WLVsSGxubY/0ffviBuLg43evSpUsUL16cd9555xVHnlX4pdu0nr6HLVEJmJkY8c1bvkzrVB1rc7nQIIQQ4skMmoSnTJlC79696dOnD5UqVWLatGmUKlWKWbNyngrS3t4eV1dX3evQoUPcunWLnj17vuLItRRF4be9MbzzcxhXbt/Hw9GKVR8G8m6d0qhUsvqREEKI3BnsVC09PZ3Dhw/zxRdfZClv3rw5YWFhz9TG3Llzadq0KR4eHk+sk5aWRlpamm47KSnp+QJ+TFJqBl+sjGB9RBwAQVVc+e6dqthZmOZJ+0IIIQo/g50JJyYmolarcXHJOmeyi4sL8fHxT90/Li6OjRs30qdPn1zrTZw4EXt7e92rcuXKLxT3Q4nJ6eyITsDESMXoNpWZ9V5NScBCCCH0YvCblo9ftlUU5Zku5f72228UK1aM4ODgXOsNHz6coUOH6ravXLmSJ4nY08maaZ1r4GhjRs3SDi/cnhBCiKLHYEnYyckJY2PjbGe9CQkJ2c6OH6coCvPmzaNbt26YmZnlWtfc3Bxzc3Pd9t27d58/6MfIykdCCCFehMEuR5uZmeHn50doaGiW8tDQUAIDA3Pdd+fOnZw9e5bevXu/zBCFEEKIl8qgl6OHDh1Kt27d8Pf3JyAggNmzZxMbG0u/fv0A7aXkK1eu8Pvvv2fZb+7cudSpUwcfHx9DhC2EEELkCYMm4U6dOnHjxg3Gjx9PXFwcPj4+bNiwQTfaOS4uLtszw3fu3GHlypX88MMPhghZCCGEyDMqRVEUQwfxKl2+fJlSpUpx6dIlSpaU+ZyFEELkLX3yjMGnrRRCCCGKKoM/ovSqaTQaQHupWwghhMhrD/PLw3yTmyKXhK9duwZA7dq1DRyJEEKIwuzatWuULl061zpF7p5wZmYmR48excXFBSOjF7san5SUROXKlYmMjMTWVlZLyo301bORfnp20lfPRvrp2eVVX2k0Gq5du0aNGjUwMcn9XLfIJeG8dPfuXezt7blz5w52dnaGDidfk756NtJPz0766tlIPz07Q/SVDMwSQgghDESSsBBCCGEgkoRfgLm5OWPGjMkyN7XImfTVs5F+enbSV89G+unZGaKv5J6wEEIIYSByJiyEEEIYiCRhIYQQwkAkCQshhBAGIkn4Oc2cORNPT08sLCzw8/Nj9+7dhg4pX9q1axdt27bF3d0dlUrFmjVrDB1SvjRx4kRq1aqFra0tzs7OBAcHEx0dbeiw8p1Zs2ZRtWpV7OzssLOzIyAggI0bNxo6rHxv4sSJqFQqhgwZYuhQ8p2xY8eiUqmyvFxdXV/Z8SUJP4dly5YxZMgQRo4cydGjR6lXrx4tW7bMtuyigJSUFKpVq8aMGTMMHUq+tnPnTvr378/+/fsJDQ0lMzOT5s2bk5KSYujQ8pWSJUsyadIkDh06xKFDh2jcuDHt2rXj5MmThg4t3zp48CCzZ8+matWqhg4l36pSpQpxcXG6V0RExKs7uCL0Vrt2baVfv35ZyipWrKh88cUXBoqoYACU1atXGzqMAiEhIUEBlJ07dxo6lHzPwcFB+fXXXw0dRr6UlJSklC9fXgkNDVUaNGigDB482NAh5TtjxoxRqlWrZrDjy5mwntLT0zl8+DDNmzfPUt68eXPCwsIMFJUobO7cuQNA8eLFDRxJ/qVWq1m6dCkpKSkEBAQYOpx8qX///rRu3ZqmTZsaOpR87cyZM7i7u+Pp6Unnzp05f/78Kzt2kVtF6UUlJiaiVqtxcXHJUu7i4kJ8fLyBohKFiaIoDB06lLp16+Lj42PocPKdiIgIAgICSE1NxcbGhtWrV1O5cmVDh5XvLF26lCNHjnDw4EFDh5Kv1alTh99//50KFSpw7do1JkyYQGBgICdPnsTR0fGlH1+S8HNSqVRZthVFyVYmxPMYMGAAx48fZ8+ePYYOJV/y9vYmPDyc27dvs3LlSkJCQti5c6ck4v+4dOkSgwcPZvPmzVhYWBg6nHytZcuWuve+vr4EBARQtmxZFixYwNChQ1/68SUJ68nJyQljY+NsZ70JCQnZzo6F0NfAgQNZu3Ytu3btomTJkoYOJ18yMzOjXLlyAPj7+3Pw4EF++OEHfvnlFwNHln8cPnyYhIQE/Pz8dGVqtZpdu3YxY8YM0tLSMDY2NmCE+Ze1tTW+vr6cOXPmlRxP7gnryczMDD8/P0JDQ7OUh4aGEhgYaKCoREGnKAoDBgxg1apVbNu2DU9PT0OHVGAoikJaWpqhw8hXmjRpQkREBOHh4bqXv78/Xbt2JTw8XBJwLtLS0oiKisLNze2VHE/OhJ/D0KFD6datG/7+/gQEBDB79mxiY2Pp16+foUPLd5KTkzl79qxuOyYmhvDwcIoXL07p0qUNGFn+0r9/f/744w/++usvbG1tdVda7O3tsbS0NHB0+ceIESNo2bIlpUqVIikpiaVLl7Jjxw42bdpk6NDyFVtb22zjCaytrXF0dJRxBo/55JNPaNu2LaVLlyYhIYEJEyZw9+5dQkJCXsnxJQk/h06dOnHjxg3Gjx9PXFwcPj4+bNiwAQ8PD0OHlu8cOnSIRo0a6bYf3mMJCQnht99+M1BU+c+sWbMAaNiwYZby+fPn06NHj1cfUD517do1unXrRlxcHPb29lStWpVNmzbRrFkzQ4cmCqjLly/TpUsXEhMTKVGiBK+//jr79+9/Zb/PZRUlIYQQwkDknrAQQghhIJKEhRBCCAORJCyEEEIYiCRhIYQQwkAkCQshhBAGIklYCCGEMBBJwkIIIYSBSBIWQgghDESSsBAiz6hUKtasWWPoMIQoMCQJC1FI9OjRA5VKle0VFBRk6NCEEE8gc0cLUYgEBQUxf/78LGXm5uYGikYI8TRyJixEIWJubo6rq2uWl4ODA6C9VDxr1ixatmyJpaUlnp6erFixIsv+ERERNG7cGEtLSxwdHenbty/JyclZ6sybN48qVapgbm6Om5sbAwYMyPJ5YmIib731FlZWVpQvX561a9fqPrt16xZdu3alRIkSWFpaUr58+Wx/NAhRlEgSFqIIGTVqFO3bt+fYsWO89957dOnShaioKADu3btHUFAQDg4OHDx4kBUrVrBly5YsSXbWrFn079+fvn37EhERwdq1aylXrlyWY4wbN46OHTty/PhxWrVqRdeuXbl586bu+JGRkWzcuJGoqChmzZqFk5PTq+sAIfIbRQhRKISEhCjGxsaKtbV1ltf48eMVRVEUQOnXr1+WferUqaN8+OGHiqIoyuzZsxUHBwclOTlZ9/n69esVIyMjJT4+XlEURXF3d1dGjhz5xBgA5csvv9RtJycnKyqVStm4caOiKIrStm1bpWfPnnnzhYUoBOSesBCFSKNGjXRrEz9UvHhx3fuAgIAsnwUEBBAeHg5AVFQU1apVw9raWvf5G2+8gUajITo6GpVKxdWrV2nSpEmuMVStWlX33traGltbWxISEgD48MMPad++PUeOHKF58+YEBwcTGBj4XN9ViMJAkrAQhYi1tXW2y8NPo1KpAFAURfc+pzqWlpbP1J6pqWm2fTUaDQAtW7bk4sWLrF+/ni1bttCkSRP69+/P999/r1fMQhQWck9YiCJk//792bYrVqwIQOXKlQkPDyclJUX3+d69ezEyMqJChQrY2tpSpkwZtm7d+kIxlChRgh49erBo0SKmTZvG7NmzX6g9IQoyORMWohBJS0sjPj4+S5mJiYlu8NOKFSvw9/enbt26LF68mAMHDjB37lwAunbtypgxYwgJCWHs2LFcv36dgQMH0q1bN1xcXAAYO3Ys/fr1w9nZmZYtW5KUlMTevXsZOHDgM8U3evRo/Pz8qFKlCmlpaaxbt45KlSrlYQ8IUbBIEhaiENm0aRNubm5Zyry9vTl16hSgHbm8dOlSPvroI1xdXVm8eDGVK1cGwMrKin/++YfBgwdTq1YtrKysaN++PVOmTNG1FRISQmpqKlOnTuWTTz7BycmJDh06PHN8ZmZmDB8+nAsXLmBpaUm9evVYunRpHnxzIQomlaIoiqGDEEK8fCqVitWrVxMcHGzoUIQQD8g9YSGEEMJAJAkLIYQQBiL3hIUoIuTOkxD5j5wJCyGEEAYiSVgIIYQwEEnCQgghhIFIEhZCCCEMRJKwEEIIYSCShIUQQggDkSQshBBCGIgkYSGEEMJAJAkLIYQQBvJ/dP47fZd4874AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_accs))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_accs))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_accs, val_accs, label=\"accuracy\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从图 6.17 的准确率曲线可以看出，模型在第 4 到 5 个训练周期后，训练和验证准确率均达到了较高水平。\n",
    "\n",
    "需要注意的是，我们之前在使用 train_classifier_simple 函数时将 eval_iter 设置为 5，这意味着我们的训练和验证性能估计仅基于 5 个批次，目的是为了提高训练效率。\n",
    "\n",
    "现在，我们将通过运行以下代码，计算整个数据集在训练集、验证集和测试集上的性能指标，这次不需要定义 eval_iter 值："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 97.21%\n",
      "Validation accuracy: 97.32%\n",
      "Test accuracy: 95.67%\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.8 将 LLM 用于垃圾短信分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 6.12 Using the model to classify new texts\n",
    "def classify_review(text, model, tokenizer, device, max_length=None, pad_token_id=50256):\n",
    "    model.eval()\n",
    "\n",
    "    input_ids = tokenizer.encode(text)                                   #A\n",
    "    supported_context_length = model.pos_emb.weight.shape[1]\n",
    "\n",
    "    input_ids = input_ids[:min(max_length, supported_context_length)]    #B\n",
    "\n",
    "    input_ids += [pad_token_id] * (max_length - len(input_ids))          #C\n",
    "    input_tensor = torch.tensor(input_ids, device=device).unsqueeze(0)   #D\n",
    "\n",
    "    with torch.no_grad():                                                #E\n",
    "        logits = model(input_tensor)[:, -1, :]                           #F\n",
    "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "    return \"spam\" if predicted_label == 1 else \"not spam\"                #G\n",
    "\n",
    "\n",
    "#A 准备模型输入\n",
    "#B 截断过长序列\n",
    "#C 填充序列至最长长度\n",
    "#D 增加批次维度\n",
    "#E 关闭梯度跟踪，进行模型推理\n",
    "#F 获取最后一个输出 token 的 logits\n",
    "#G 返回分类结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n"
     ]
    }
   ],
   "source": [
    "text_1 = (\n",
    "    \"You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_1, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not spam\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Hey, just wanted to check if we're still on\"\n",
    "    \" for dinner tonight? Let me know!\"\n",
    ")\n",
    "print(classify_review(\n",
    "    text_2, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"review_classifier.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_state_dict = torch.load(\"review_classifier.pth\")\n",
    "model.load_state_dict(model_state_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3c06e3e46abf38078fe4dac36a0085ec2b134ebbd73dd076183d243eeca6918f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
